{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This license has also been called the \"New BSD License\" or \n",
    "\"Modified BSD License\". See also the 2-clause BSD License.\n",
    "\n",
    "Copyright Â© 2018-2019 - General Electric Company, All Rights Reserved\n",
    " \n",
    "Project: ANSWER, developed with the support of the Defense Advanced \n",
    "Research Projects Agency (DARPA) under Agreement  No.  HR00111990006. \n",
    " \n",
    "Redistribution and use in source and binary forms, with or without \n",
    "modification, are permitted provided that the following conditions are met:\n",
    "\n",
    " 1. Redistributions of source code must retain the above copyright notice, \n",
    "     this list of conditions and the following disclaimer.\n",
    "\n",
    " 2. Redistributions in binary form must reproduce the above copyright notice, \n",
    "     this list of conditions and the following disclaimer in the documentation \n",
    "     and/or other materials provided with the distribution.\n",
    "\n",
    " 3. Neither the name of the copyright holder nor the names of its \n",
    "    contributors may be used to endorse or promote products derived \n",
    "     from this software without specific prior written permission.\n",
    "\n",
    " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" \n",
    " AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE \n",
    " IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE \n",
    " ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE \n",
    " LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR \n",
    " CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF \n",
    " SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS \n",
    " INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN \n",
    " CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) \n",
    " ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF \n",
    " THE POSSIBILITY OF SUCH DAMAGE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is used to train a BI-LSTM-CRF Sequence Tagger model\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-24 16:11:28,689 Reading data from dataset/nasa-website/annotations/data\n",
      "2019-01-24 16:11:28,691 Train: dataset/nasa-website/annotations/data/trainEquations.txt\n",
      "2019-01-24 16:11:28,693 Dev: None\n",
      "2019-01-24 16:11:28,695 Test: dataset/nasa-website/annotations/data/testEquations.txt\n"
     ]
    }
   ],
   "source": [
    "from flair.data import TaggedCorpus\n",
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "\n",
    "#main data dir : nasa-website\n",
    "base_path = 'dataset/nasa-website/annotations/'\n",
    "data_folder = base_path + 'data/'\n",
    "\n",
    "columns = {0: 'text', 1: 'ner'}\n",
    "\n",
    "corpus: TaggedCorpus = NLPTaskDataFetcher.load_column_corpus(data_folder, columns,\n",
    "                                                              train_file='trainEquations.txt',\n",
    "                                                              test_file='testEquations.txt')\n",
    "#                                                              dev_file='train.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2281"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus.train)\n",
    "#print(corpus.train[0].to_tagged_string('ner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'<unk>', b'O', b'B-CONCEPT', b'I-CONCEPT', b'B-EQUATION', b'I-EQUATION', b'O\"', b'B-CONCEPT\"', b'<START>', b'<STOP>']\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import TokenEmbeddings, CharacterEmbeddings, WordEmbeddings, StackedEmbeddings\n",
    "from typing import List\n",
    "\n",
    "tag_type = 'ner'\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "print(tag_dictionary.idx2item)\n",
    "\n",
    "embedding_types: List[TokenEmbeddings] = [\n",
    "\n",
    "    WordEmbeddings('glove'),\n",
    "\n",
    "    # comment in this line to use character embeddings\n",
    "    CharacterEmbeddings(),\n",
    "\n",
    "    # comment in these lines to use flair embeddings\n",
    "    # FlairEmbeddings('news-forward'),\n",
    "    # FlairEmbeddings('news-backward'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type=tag_type,\n",
    "                                        use_crf=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-24 16:11:51,612 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:11:51,614 Evaluation method: MICRO_F1_SCORE\n",
      "2019-01-24 16:11:51,616 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:11:52,525 epoch 1 - iter 0/72 - loss 51.76071167\n",
      "2019-01-24 16:11:56,704 epoch 1 - iter 7/72 - loss 19.21198165\n",
      "2019-01-24 16:12:00,577 epoch 1 - iter 14/72 - loss 12.25069197\n",
      "2019-01-24 16:12:04,549 epoch 1 - iter 21/72 - loss 9.49504805\n",
      "2019-01-24 16:12:09,277 epoch 1 - iter 28/72 - loss 8.18955206\n",
      "2019-01-24 16:12:13,796 epoch 1 - iter 35/72 - loss 7.27675532\n",
      "2019-01-24 16:12:17,765 epoch 1 - iter 42/72 - loss 6.66108679\n",
      "2019-01-24 16:12:21,490 epoch 1 - iter 49/72 - loss 6.12638412\n",
      "2019-01-24 16:12:25,619 epoch 1 - iter 56/72 - loss 5.78524303\n",
      "2019-01-24 16:12:29,677 epoch 1 - iter 63/72 - loss 5.44226931\n",
      "2019-01-24 16:12:33,853 epoch 1 - iter 70/72 - loss 5.15604994\n",
      "2019-01-24 16:12:34,089 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:12:34,091 EPOCH 1 done: loss 5.1421 - lr 0.1000 - bad epochs 0\n",
      "2019-01-24 16:12:35,432 DEV  : loss 1.93155313 - f-score 0.3151 - acc 0.3151\n",
      "2019-01-24 16:12:42,203 TEST : loss 2.28938580 - f-score 0.2647 - acc 0.2647\n",
      "2019-01-24 16:12:44,661 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:12:45,277 epoch 2 - iter 0/72 - loss 2.06117272\n",
      "2019-01-24 16:12:49,520 epoch 2 - iter 7/72 - loss 2.51673909\n",
      "2019-01-24 16:12:53,549 epoch 2 - iter 14/72 - loss 2.37495318\n",
      "2019-01-24 16:12:57,952 epoch 2 - iter 21/72 - loss 2.50650363\n",
      "2019-01-24 16:13:02,352 epoch 2 - iter 28/72 - loss 2.35617045\n",
      "2019-01-24 16:13:06,795 epoch 2 - iter 35/72 - loss 2.26849487\n",
      "2019-01-24 16:13:11,007 epoch 2 - iter 42/72 - loss 2.23257502\n",
      "2019-01-24 16:13:14,971 epoch 2 - iter 49/72 - loss 2.16885681\n",
      "2019-01-24 16:13:19,224 epoch 2 - iter 56/72 - loss 2.19925167\n",
      "2019-01-24 16:13:23,538 epoch 2 - iter 63/72 - loss 2.15045565\n",
      "2019-01-24 16:13:27,788 epoch 2 - iter 70/72 - loss 2.10215823\n",
      "2019-01-24 16:13:28,037 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:13:28,038 EPOCH 2 done: loss 2.0978 - lr 0.1000 - bad epochs 0\n",
      "2019-01-24 16:13:29,384 DEV  : loss 1.16673517 - f-score 0.6178 - acc 0.6178\n",
      "2019-01-24 16:13:36,990 TEST : loss 1.48273611 - f-score 0.6445 - acc 0.6444\n",
      "2019-01-24 16:13:39,519 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:13:40,233 epoch 3 - iter 0/72 - loss 1.83900571\n",
      "2019-01-24 16:13:44,705 epoch 3 - iter 7/72 - loss 1.92284748\n",
      "2019-01-24 16:13:49,454 epoch 3 - iter 14/72 - loss 2.00807913\n",
      "2019-01-24 16:13:53,638 epoch 3 - iter 21/72 - loss 1.99993068\n",
      "2019-01-24 16:13:57,829 epoch 3 - iter 28/72 - loss 2.03570039\n",
      "2019-01-24 16:14:02,011 epoch 3 - iter 35/72 - loss 1.98166770\n",
      "2019-01-24 16:14:06,181 epoch 3 - iter 42/72 - loss 1.84807039\n",
      "2019-01-24 16:14:10,316 epoch 3 - iter 49/72 - loss 1.85013357\n",
      "2019-01-24 16:14:14,848 epoch 3 - iter 56/72 - loss 1.80544202\n",
      "2019-01-24 16:14:18,906 epoch 3 - iter 63/72 - loss 1.74594003\n",
      "2019-01-24 16:14:23,240 epoch 3 - iter 70/72 - loss 1.73549598\n",
      "2019-01-24 16:14:23,443 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:14:23,445 EPOCH 3 done: loss 1.7452 - lr 0.1000 - bad epochs 0\n",
      "2019-01-24 16:14:24,807 DEV  : loss 1.00870919 - f-score 0.6339 - acc 0.6339\n",
      "2019-01-24 16:14:32,280 TEST : loss 1.21563172 - f-score 0.6538 - acc 0.6537\n",
      "2019-01-24 16:14:34,925 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:14:35,640 epoch 4 - iter 0/72 - loss 1.70714831\n",
      "2019-01-24 16:14:40,184 epoch 4 - iter 7/72 - loss 1.90951598\n",
      "2019-01-24 16:14:44,386 epoch 4 - iter 14/72 - loss 1.80473838\n",
      "2019-01-24 16:14:48,771 epoch 4 - iter 21/72 - loss 1.72694541\n",
      "2019-01-24 16:14:52,991 epoch 4 - iter 28/72 - loss 1.74423987\n",
      "2019-01-24 16:14:56,989 epoch 4 - iter 35/72 - loss 1.69502422\n",
      "2019-01-24 16:15:00,974 epoch 4 - iter 42/72 - loss 1.65945432\n",
      "2019-01-24 16:15:04,987 epoch 4 - iter 49/72 - loss 1.63618396\n",
      "2019-01-24 16:15:08,923 epoch 4 - iter 56/72 - loss 1.59744450\n",
      "2019-01-24 16:15:12,960 epoch 4 - iter 63/72 - loss 1.61878865\n",
      "2019-01-24 16:15:17,403 epoch 4 - iter 70/72 - loss 1.59820480\n",
      "2019-01-24 16:15:17,632 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:15:17,634 EPOCH 4 done: loss 1.5974 - lr 0.1000 - bad epochs 0\n",
      "2019-01-24 16:15:18,945 DEV  : loss 0.87430996 - f-score 0.6559 - acc 0.6559\n",
      "2019-01-24 16:15:25,725 TEST : loss 1.15246248 - f-score 0.6750 - acc 0.6750\n",
      "2019-01-24 16:15:28,246 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:15:28,827 epoch 5 - iter 0/72 - loss 1.79878044\n",
      "2019-01-24 16:15:33,152 epoch 5 - iter 7/72 - loss 1.83123197\n",
      "2019-01-24 16:15:37,026 epoch 5 - iter 14/72 - loss 1.60276638\n",
      "2019-01-24 16:15:40,982 epoch 5 - iter 21/72 - loss 1.48168375\n",
      "2019-01-24 16:15:45,058 epoch 5 - iter 28/72 - loss 1.53369305\n",
      "2019-01-24 16:15:49,554 epoch 5 - iter 35/72 - loss 1.54210650\n",
      "2019-01-24 16:15:53,489 epoch 5 - iter 42/72 - loss 1.49867699\n",
      "2019-01-24 16:15:57,898 epoch 5 - iter 49/72 - loss 1.48005119\n",
      "2019-01-24 16:16:02,035 epoch 5 - iter 56/72 - loss 1.42938845\n",
      "2019-01-24 16:16:06,366 epoch 5 - iter 63/72 - loss 1.45385785\n",
      "2019-01-24 16:16:10,467 epoch 5 - iter 70/72 - loss 1.43424113\n",
      "2019-01-24 16:16:10,668 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:16:10,669 EPOCH 5 done: loss 1.4295 - lr 0.1000 - bad epochs 0\n",
      "2019-01-24 16:16:12,030 DEV  : loss 1.28019440 - f-score 0.5061 - acc 0.5062\n",
      "2019-01-24 16:16:18,864 TEST : loss 1.56438899 - f-score 0.4994 - acc 0.4994\n",
      "2019-01-24 16:16:21,391 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:16:22,069 epoch 6 - iter 0/72 - loss 1.25851178\n",
      "2019-01-24 16:16:25,843 epoch 6 - iter 7/72 - loss 1.53549590\n",
      "2019-01-24 16:16:29,961 epoch 6 - iter 14/72 - loss 1.70672517\n",
      "2019-01-24 16:16:34,472 epoch 6 - iter 21/72 - loss 1.85370656\n",
      "2019-01-24 16:16:38,705 epoch 6 - iter 28/72 - loss 1.65032044\n",
      "2019-01-24 16:16:42,819 epoch 6 - iter 35/72 - loss 1.57470329\n",
      "2019-01-24 16:16:46,840 epoch 6 - iter 42/72 - loss 1.51201216\n",
      "2019-01-24 16:16:50,744 epoch 6 - iter 49/72 - loss 1.46031717\n",
      "2019-01-24 16:16:55,508 epoch 6 - iter 56/72 - loss 1.39536954\n",
      "2019-01-24 16:16:59,655 epoch 6 - iter 63/72 - loss 1.40881836\n",
      "2019-01-24 16:17:04,303 epoch 6 - iter 70/72 - loss 1.40706431\n",
      "2019-01-24 16:17:04,623 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:17:04,625 EPOCH 6 done: loss 1.4110 - lr 0.1000 - bad epochs 0\n",
      "2019-01-24 16:17:05,950 DEV  : loss 0.72197294 - f-score 0.6989 - acc 0.6989\n",
      "2019-01-24 16:17:12,803 TEST : loss 0.97019988 - f-score 0.7092 - acc 0.7092\n",
      "2019-01-24 16:17:15,330 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:17:16,012 epoch 7 - iter 0/72 - loss 0.62919772\n",
      "2019-01-24 16:17:20,500 epoch 7 - iter 7/72 - loss 1.18034077\n",
      "2019-01-24 16:17:24,844 epoch 7 - iter 14/72 - loss 1.34342626\n",
      "2019-01-24 16:17:29,069 epoch 7 - iter 21/72 - loss 1.39919736\n",
      "2019-01-24 16:17:33,215 epoch 7 - iter 28/72 - loss 1.29607706\n",
      "2019-01-24 16:17:37,185 epoch 7 - iter 35/72 - loss 1.22217328\n",
      "2019-01-24 16:17:41,804 epoch 7 - iter 42/72 - loss 1.18630198\n",
      "2019-01-24 16:17:46,474 epoch 7 - iter 49/72 - loss 1.23594412\n",
      "2019-01-24 16:17:50,388 epoch 7 - iter 56/72 - loss 1.27361770\n",
      "2019-01-24 16:17:54,501 epoch 7 - iter 63/72 - loss 1.25075951\n",
      "2019-01-24 16:17:58,636 epoch 7 - iter 70/72 - loss 1.23466724\n",
      "2019-01-24 16:17:58,852 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:17:58,854 EPOCH 7 done: loss 1.2345 - lr 0.1000 - bad epochs 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-24 16:18:00,409 DEV  : loss 0.65241188 - f-score 0.7487 - acc 0.7487\n",
      "2019-01-24 16:18:08,060 TEST : loss 0.85083598 - f-score 0.7502 - acc 0.7502\n",
      "2019-01-24 16:18:10,578 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:18:11,189 epoch 8 - iter 0/72 - loss 0.53701812\n",
      "2019-01-24 16:18:15,317 epoch 8 - iter 7/72 - loss 0.80177581\n",
      "2019-01-24 16:18:19,579 epoch 8 - iter 14/72 - loss 0.92357865\n",
      "2019-01-24 16:18:23,467 epoch 8 - iter 21/72 - loss 0.94912175\n",
      "2019-01-24 16:18:27,701 epoch 8 - iter 28/72 - loss 1.06683644\n",
      "2019-01-24 16:18:32,394 epoch 8 - iter 35/72 - loss 1.08887915\n",
      "2019-01-24 16:18:36,619 epoch 8 - iter 42/72 - loss 1.10253578\n",
      "2019-01-24 16:18:40,726 epoch 8 - iter 49/72 - loss 1.14119890\n",
      "2019-01-24 16:18:45,056 epoch 8 - iter 56/72 - loss 1.14014819\n",
      "2019-01-24 16:18:49,365 epoch 8 - iter 63/72 - loss 1.12694796\n",
      "2019-01-24 16:18:53,448 epoch 8 - iter 70/72 - loss 1.13344307\n",
      "2019-01-24 16:18:53,733 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:18:53,735 EPOCH 8 done: loss 1.1356 - lr 0.1000 - bad epochs 0\n",
      "2019-01-24 16:18:55,096 DEV  : loss 0.80514574 - f-score 0.6989 - acc 0.6989\n",
      "2019-01-24 16:19:02,267 TEST : loss 0.97791195 - f-score 0.6986 - acc 0.6986\n",
      "2019-01-24 16:19:04,796 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:19:05,429 epoch 9 - iter 0/72 - loss 1.42649984\n",
      "2019-01-24 16:19:09,537 epoch 9 - iter 7/72 - loss 1.10860998\n",
      "2019-01-24 16:19:13,614 epoch 9 - iter 14/72 - loss 1.29548599\n",
      "2019-01-24 16:19:17,541 epoch 9 - iter 21/72 - loss 1.24425163\n",
      "2019-01-24 16:19:21,530 epoch 9 - iter 28/72 - loss 1.09883763\n",
      "2019-01-24 16:19:26,169 epoch 9 - iter 35/72 - loss 1.07031960\n",
      "2019-01-24 16:19:30,806 epoch 9 - iter 42/72 - loss 1.06555076\n",
      "2019-01-24 16:19:35,090 epoch 9 - iter 49/72 - loss 1.02037686\n",
      "2019-01-24 16:19:39,301 epoch 9 - iter 56/72 - loss 1.02475299\n",
      "2019-01-24 16:19:43,813 epoch 9 - iter 63/72 - loss 1.00294878\n",
      "2019-01-24 16:19:48,390 epoch 9 - iter 70/72 - loss 1.02172128\n",
      "2019-01-24 16:19:48,787 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:19:48,789 EPOCH 9 done: loss 1.0268 - lr 0.1000 - bad epochs 0\n",
      "2019-01-24 16:19:50,445 DEV  : loss 0.66491765 - f-score 0.7873 - acc 0.7873\n",
      "2019-01-24 16:19:57,320 TEST : loss 0.89212394 - f-score 0.7760 - acc 0.7760\n",
      "2019-01-24 16:19:59,878 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:20:00,471 epoch 10 - iter 0/72 - loss 0.88717341\n",
      "2019-01-24 16:20:04,708 epoch 10 - iter 7/72 - loss 0.87372168\n",
      "2019-01-24 16:20:09,183 epoch 10 - iter 14/72 - loss 0.99382485\n",
      "2019-01-24 16:20:13,365 epoch 10 - iter 21/72 - loss 0.98459276\n",
      "2019-01-24 16:20:18,094 epoch 10 - iter 28/72 - loss 1.02751114\n",
      "2019-01-24 16:20:22,314 epoch 10 - iter 35/72 - loss 0.99163317\n",
      "2019-01-24 16:20:26,426 epoch 10 - iter 42/72 - loss 0.96257474\n",
      "2019-01-24 16:20:30,885 epoch 10 - iter 49/72 - loss 0.94974695\n",
      "2019-01-24 16:20:35,226 epoch 10 - iter 56/72 - loss 0.95979973\n",
      "2019-01-24 16:20:39,797 epoch 10 - iter 63/72 - loss 0.95656255\n",
      "2019-01-24 16:20:44,039 epoch 10 - iter 70/72 - loss 0.99209943\n",
      "2019-01-24 16:20:44,320 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:20:44,321 EPOCH 10 done: loss 0.9908 - lr 0.1000 - bad epochs 0\n",
      "2019-01-24 16:20:46,103 DEV  : loss 0.63887656 - f-score 0.7879 - acc 0.7879\n",
      "2019-01-24 16:20:53,973 TEST : loss 0.75140315 - f-score 0.7916 - acc 0.7916\n",
      "2019-01-24 16:20:56,500 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:20:57,179 epoch 11 - iter 0/72 - loss 0.25234616\n",
      "2019-01-24 16:21:01,229 epoch 11 - iter 7/72 - loss 0.72976178\n",
      "2019-01-24 16:21:05,495 epoch 11 - iter 14/72 - loss 0.84885181\n",
      "2019-01-24 16:21:10,146 epoch 11 - iter 21/72 - loss 0.93785896\n",
      "2019-01-24 16:21:14,344 epoch 11 - iter 28/72 - loss 0.91172851\n",
      "2019-01-24 16:21:18,557 epoch 11 - iter 35/72 - loss 0.91263624\n",
      "2019-01-24 16:21:22,762 epoch 11 - iter 42/72 - loss 0.96570819\n",
      "2019-01-24 16:21:26,886 epoch 11 - iter 49/72 - loss 0.94840237\n",
      "2019-01-24 16:21:31,286 epoch 11 - iter 56/72 - loss 0.95848226\n",
      "2019-01-24 16:21:35,587 epoch 11 - iter 63/72 - loss 0.93367493\n",
      "2019-01-24 16:21:39,974 epoch 11 - iter 70/72 - loss 0.91849943\n",
      "2019-01-24 16:21:40,292 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:21:40,294 EPOCH 11 done: loss 0.9164 - lr 0.1000 - bad epochs 0\n",
      "2019-01-24 16:21:41,772 DEV  : loss 0.47994289 - f-score 0.8465 - acc 0.8465\n",
      "2019-01-24 16:21:48,704 TEST : loss 0.64578116 - f-score 0.8305 - acc 0.8305\n",
      "2019-01-24 16:21:51,237 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:21:51,813 epoch 12 - iter 0/72 - loss 1.11315227\n",
      "2019-01-24 16:21:55,966 epoch 12 - iter 7/72 - loss 0.95486772\n",
      "2019-01-24 16:22:00,540 epoch 12 - iter 14/72 - loss 0.87829512\n",
      "2019-01-24 16:22:04,653 epoch 12 - iter 21/72 - loss 0.83979837\n",
      "2019-01-24 16:22:08,867 epoch 12 - iter 28/72 - loss 0.82744652\n",
      "2019-01-24 16:22:13,306 epoch 12 - iter 35/72 - loss 0.83184957\n",
      "2019-01-24 16:22:17,435 epoch 12 - iter 42/72 - loss 0.84341741\n",
      "2019-01-24 16:22:21,485 epoch 12 - iter 49/72 - loss 0.84816880\n",
      "2019-01-24 16:22:25,515 epoch 12 - iter 56/72 - loss 0.84892768\n",
      "2019-01-24 16:22:29,761 epoch 12 - iter 63/72 - loss 0.84684918\n",
      "2019-01-24 16:22:34,092 epoch 12 - iter 70/72 - loss 0.85304345\n",
      "2019-01-24 16:22:34,320 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:22:34,322 EPOCH 12 done: loss 0.8581 - lr 0.1000 - bad epochs 0\n",
      "2019-01-24 16:22:36,121 DEV  : loss 0.53330284 - f-score 0.8558 - acc 0.8558\n",
      "2019-01-24 16:22:43,964 TEST : loss 0.75551909 - f-score 0.8359 - acc 0.8359\n",
      "2019-01-24 16:22:46,502 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:22:47,266 epoch 13 - iter 0/72 - loss 2.75402975\n",
      "2019-01-24 16:22:51,512 epoch 13 - iter 7/72 - loss 1.19122598\n",
      "2019-01-24 16:22:55,828 epoch 13 - iter 14/72 - loss 1.04182367\n",
      "2019-01-24 16:23:00,292 epoch 13 - iter 21/72 - loss 0.93989664\n",
      "2019-01-24 16:23:04,403 epoch 13 - iter 28/72 - loss 0.87518599\n",
      "2019-01-24 16:23:08,862 epoch 13 - iter 35/72 - loss 0.85849291\n",
      "2019-01-24 16:23:12,873 epoch 13 - iter 42/72 - loss 0.88641882\n",
      "2019-01-24 16:23:17,273 epoch 13 - iter 49/72 - loss 0.85040255\n",
      "2019-01-24 16:23:21,564 epoch 13 - iter 56/72 - loss 0.84756767\n",
      "2019-01-24 16:23:26,002 epoch 13 - iter 63/72 - loss 0.82972791\n",
      "2019-01-24 16:23:30,372 epoch 13 - iter 70/72 - loss 0.85585535\n",
      "2019-01-24 16:23:30,609 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:23:30,611 EPOCH 13 done: loss 0.8541 - lr 0.1000 - bad epochs 0\n",
      "2019-01-24 16:23:31,974 DEV  : loss 0.56443816 - f-score 0.7961 - acc 0.7960\n",
      "2019-01-24 16:23:39,884 TEST : loss 0.69400114 - f-score 0.8068 - acc 0.8068\n",
      "2019-01-24 16:23:42,417 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:23:43,244 epoch 14 - iter 0/72 - loss 1.15592730\n",
      "2019-01-24 16:23:48,129 epoch 14 - iter 7/72 - loss 1.24172910\n",
      "2019-01-24 16:23:52,345 epoch 14 - iter 14/72 - loss 1.02273805\n",
      "2019-01-24 16:23:56,679 epoch 14 - iter 21/72 - loss 0.89270024\n",
      "2019-01-24 16:24:01,326 epoch 14 - iter 28/72 - loss 0.92355351\n",
      "2019-01-24 16:24:05,807 epoch 14 - iter 35/72 - loss 0.90753856\n",
      "2019-01-24 16:24:10,048 epoch 14 - iter 42/72 - loss 0.92937589\n",
      "2019-01-24 16:24:14,129 epoch 14 - iter 49/72 - loss 0.93695336\n",
      "2019-01-24 16:24:18,307 epoch 14 - iter 56/72 - loss 0.89308165\n",
      "2019-01-24 16:24:22,542 epoch 14 - iter 63/72 - loss 0.90022950\n",
      "2019-01-24 16:24:26,664 epoch 14 - iter 70/72 - loss 0.86387120\n",
      "2019-01-24 16:24:26,890 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:24:26,892 EPOCH 14 done: loss 0.8615 - lr 0.1000 - bad epochs 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-24 16:24:28,239 DEV  : loss 0.48120484 - f-score 0.8651 - acc 0.8651\n",
      "2019-01-24 16:24:35,129 TEST : loss 0.67114699 - f-score 0.8355 - acc 0.8355\n",
      "2019-01-24 16:24:35,133 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:24:35,707 epoch 15 - iter 0/72 - loss 1.71474981\n",
      "2019-01-24 16:24:40,029 epoch 15 - iter 7/72 - loss 1.05520684\n",
      "2019-01-24 16:24:44,245 epoch 15 - iter 14/72 - loss 1.00095525\n",
      "2019-01-24 16:24:48,824 epoch 15 - iter 21/72 - loss 0.91639448\n",
      "2019-01-24 16:24:52,865 epoch 15 - iter 28/72 - loss 0.88583007\n",
      "2019-01-24 16:24:56,738 epoch 15 - iter 35/72 - loss 0.86349336\n",
      "2019-01-24 16:25:00,842 epoch 15 - iter 42/72 - loss 0.84999016\n",
      "2019-01-24 16:25:05,214 epoch 15 - iter 49/72 - loss 0.84099651\n",
      "2019-01-24 16:25:09,638 epoch 15 - iter 56/72 - loss 0.82168842\n",
      "2019-01-24 16:25:14,116 epoch 15 - iter 63/72 - loss 0.81611875\n",
      "2019-01-24 16:25:18,394 epoch 15 - iter 70/72 - loss 0.82494338\n",
      "2019-01-24 16:25:18,626 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:25:18,628 EPOCH 15 done: loss 0.8222 - lr 0.1000 - bad epochs 1\n",
      "2019-01-24 16:25:19,962 DEV  : loss 0.42907968 - f-score 0.8679 - acc 0.8679\n",
      "2019-01-24 16:25:27,250 TEST : loss 0.57367015 - f-score 0.8465 - acc 0.8466\n",
      "2019-01-24 16:25:29,785 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:25:30,393 epoch 16 - iter 0/72 - loss 0.76306808\n",
      "2019-01-24 16:25:34,630 epoch 16 - iter 7/72 - loss 0.59237566\n",
      "2019-01-24 16:25:38,861 epoch 16 - iter 14/72 - loss 0.70691851\n",
      "2019-01-24 16:25:42,974 epoch 16 - iter 21/72 - loss 0.76223115\n",
      "2019-01-24 16:25:46,766 epoch 16 - iter 28/72 - loss 0.75228736\n",
      "2019-01-24 16:25:51,165 epoch 16 - iter 35/72 - loss 0.82098712\n",
      "2019-01-24 16:25:55,445 epoch 16 - iter 42/72 - loss 0.79510823\n",
      "2019-01-24 16:25:59,515 epoch 16 - iter 49/72 - loss 0.78119603\n",
      "2019-01-24 16:26:04,016 epoch 16 - iter 56/72 - loss 0.75879541\n",
      "2019-01-24 16:26:08,380 epoch 16 - iter 63/72 - loss 0.75400597\n",
      "2019-01-24 16:26:13,184 epoch 16 - iter 70/72 - loss 0.76198691\n",
      "2019-01-24 16:26:13,440 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:26:13,442 EPOCH 16 done: loss 0.7593 - lr 0.1000 - bad epochs 0\n",
      "2019-01-24 16:26:14,858 DEV  : loss 0.45232055 - f-score 0.8531 - acc 0.8531\n",
      "2019-01-24 16:26:22,381 TEST : loss 0.60639662 - f-score 0.8554 - acc 0.8554\n",
      "2019-01-24 16:26:24,977 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:26:25,746 epoch 17 - iter 0/72 - loss 2.23986983\n",
      "2019-01-24 16:26:30,430 epoch 17 - iter 7/72 - loss 0.89517889\n",
      "2019-01-24 16:26:34,921 epoch 17 - iter 14/72 - loss 0.81321369\n",
      "2019-01-24 16:26:39,454 epoch 17 - iter 21/72 - loss 0.77351980\n",
      "2019-01-24 16:26:43,636 epoch 17 - iter 28/72 - loss 0.71178605\n",
      "2019-01-24 16:26:47,763 epoch 17 - iter 35/72 - loss 0.72945743\n",
      "2019-01-24 16:26:53,031 epoch 17 - iter 42/72 - loss 0.73921707\n",
      "2019-01-24 16:26:57,818 epoch 17 - iter 49/72 - loss 0.74289406\n",
      "2019-01-24 16:27:02,344 epoch 17 - iter 56/72 - loss 0.77475974\n",
      "2019-01-24 16:27:06,908 epoch 17 - iter 63/72 - loss 0.77932626\n",
      "2019-01-24 16:27:11,303 epoch 17 - iter 70/72 - loss 0.75778207\n",
      "2019-01-24 16:27:11,603 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:27:11,605 EPOCH 17 done: loss 0.7558 - lr 0.1000 - bad epochs 0\n",
      "2019-01-24 16:27:12,951 DEV  : loss 0.45097467 - f-score 0.8585 - acc 0.8585\n",
      "2019-01-24 16:27:19,839 TEST : loss 0.62900424 - f-score 0.8263 - acc 0.8263\n",
      "2019-01-24 16:27:22,376 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:27:23,085 epoch 18 - iter 0/72 - loss 0.82898176\n",
      "2019-01-24 16:27:27,213 epoch 18 - iter 7/72 - loss 0.56461859\n",
      "2019-01-24 16:27:31,623 epoch 18 - iter 14/72 - loss 0.52437486\n",
      "2019-01-24 16:27:35,917 epoch 18 - iter 21/72 - loss 0.55618982\n",
      "2019-01-24 16:27:40,475 epoch 18 - iter 28/72 - loss 0.53080066\n",
      "2019-01-24 16:27:44,717 epoch 18 - iter 35/72 - loss 0.61834213\n",
      "2019-01-24 16:27:48,937 epoch 18 - iter 42/72 - loss 0.65192655\n",
      "2019-01-24 16:27:53,502 epoch 18 - iter 49/72 - loss 0.68554120\n",
      "2019-01-24 16:27:57,593 epoch 18 - iter 56/72 - loss 0.68900015\n",
      "2019-01-24 16:28:01,858 epoch 18 - iter 63/72 - loss 0.69862234\n",
      "2019-01-24 16:28:05,961 epoch 18 - iter 70/72 - loss 0.71454867\n",
      "2019-01-24 16:28:06,237 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:28:06,239 EPOCH 18 done: loss 0.7129 - lr 0.1000 - bad epochs 0\n",
      "2019-01-24 16:28:07,615 DEV  : loss 0.42186570 - f-score 0.8679 - acc 0.8679\n",
      "2019-01-24 16:28:15,379 TEST : loss 0.60331404 - f-score 0.8524 - acc 0.8524\n",
      "2019-01-24 16:28:17,884 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:28:18,627 epoch 19 - iter 0/72 - loss 0.58585376\n",
      "2019-01-24 16:28:22,583 epoch 19 - iter 7/72 - loss 0.53647423\n",
      "2019-01-24 16:28:26,492 epoch 19 - iter 14/72 - loss 0.76573265\n",
      "2019-01-24 16:28:30,394 epoch 19 - iter 21/72 - loss 0.76741476\n",
      "2019-01-24 16:28:34,834 epoch 19 - iter 28/72 - loss 0.70133411\n",
      "2019-01-24 16:28:39,291 epoch 19 - iter 35/72 - loss 0.69559722\n",
      "2019-01-24 16:28:43,740 epoch 19 - iter 42/72 - loss 0.71481895\n",
      "2019-01-24 16:28:47,983 epoch 19 - iter 49/72 - loss 0.74218265\n",
      "2019-01-24 16:28:52,102 epoch 19 - iter 56/72 - loss 0.74921141\n",
      "2019-01-24 16:28:56,693 epoch 19 - iter 63/72 - loss 0.72045534\n",
      "2019-01-24 16:29:00,896 epoch 19 - iter 70/72 - loss 0.71951986\n",
      "2019-01-24 16:29:01,159 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:29:01,161 EPOCH 19 done: loss 0.7172 - lr 0.1000 - bad epochs 0\n",
      "2019-01-24 16:29:02,537 DEV  : loss 0.43519795 - f-score 0.8785 - acc 0.8785\n",
      "2019-01-24 16:29:09,597 TEST : loss 0.56340718 - f-score 0.8488 - acc 0.8488\n",
      "2019-01-24 16:29:09,600 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:29:10,179 epoch 20 - iter 0/72 - loss 1.05499315\n",
      "2019-01-24 16:29:14,615 epoch 20 - iter 7/72 - loss 0.77007405\n",
      "2019-01-24 16:29:18,816 epoch 20 - iter 14/72 - loss 0.60795100\n",
      "2019-01-24 16:29:22,980 epoch 20 - iter 21/72 - loss 0.58951354\n",
      "2019-01-24 16:29:27,186 epoch 20 - iter 28/72 - loss 0.54766886\n",
      "2019-01-24 16:29:31,478 epoch 20 - iter 35/72 - loss 0.61373954\n",
      "2019-01-24 16:29:35,571 epoch 20 - iter 42/72 - loss 0.60693397\n",
      "2019-01-24 16:29:39,467 epoch 20 - iter 49/72 - loss 0.58965900\n",
      "2019-01-24 16:29:43,686 epoch 20 - iter 56/72 - loss 0.61692571\n",
      "2019-01-24 16:29:48,041 epoch 20 - iter 63/72 - loss 0.64080157\n",
      "2019-01-24 16:29:53,055 epoch 20 - iter 70/72 - loss 0.67515136\n",
      "2019-01-24 16:29:53,398 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:29:53,401 EPOCH 20 done: loss 0.6736 - lr 0.1000 - bad epochs 1\n",
      "2019-01-24 16:29:55,168 DEV  : loss 0.41706124 - f-score 0.8207 - acc 0.8208\n",
      "2019-01-24 16:30:02,407 TEST : loss 0.54703587 - f-score 0.8508 - acc 0.8508\n",
      "2019-01-24 16:30:04,923 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:30:05,666 epoch 21 - iter 0/72 - loss 1.22401190\n",
      "2019-01-24 16:30:09,783 epoch 21 - iter 7/72 - loss 0.61480598\n",
      "2019-01-24 16:30:13,997 epoch 21 - iter 14/72 - loss 0.50014510\n",
      "2019-01-24 16:30:18,261 epoch 21 - iter 21/72 - loss 0.52554639\n",
      "2019-01-24 16:30:22,736 epoch 21 - iter 28/72 - loss 0.49898396\n",
      "2019-01-24 16:30:27,033 epoch 21 - iter 35/72 - loss 0.50949716\n",
      "2019-01-24 16:30:31,152 epoch 21 - iter 42/72 - loss 0.50490995\n",
      "2019-01-24 16:30:35,363 epoch 21 - iter 49/72 - loss 0.51059812\n",
      "2019-01-24 16:30:39,860 epoch 21 - iter 56/72 - loss 0.54725828\n",
      "2019-01-24 16:30:44,244 epoch 21 - iter 63/72 - loss 0.58763773\n",
      "2019-01-24 16:30:48,282 epoch 21 - iter 70/72 - loss 0.61047823\n",
      "2019-01-24 16:30:48,487 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-24 16:30:48,488 EPOCH 21 done: loss 0.6084 - lr 0.1000 - bad epochs 0\n",
      "2019-01-24 16:30:50,276 DEV  : loss 0.37498823 - f-score 0.8688 - acc 0.8688\n",
      "2019-01-24 16:30:57,667 TEST : loss 0.54532629 - f-score 0.8619 - acc 0.8619\n",
      "2019-01-24 16:31:00,216 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:31:00,821 epoch 22 - iter 0/72 - loss 0.57034111\n",
      "2019-01-24 16:31:04,908 epoch 22 - iter 7/72 - loss 0.54216108\n",
      "2019-01-24 16:31:09,084 epoch 22 - iter 14/72 - loss 0.44900686\n",
      "2019-01-24 16:31:13,425 epoch 22 - iter 21/72 - loss 0.49883938\n",
      "2019-01-24 16:31:17,524 epoch 22 - iter 28/72 - loss 0.55052977\n",
      "2019-01-24 16:31:21,616 epoch 22 - iter 35/72 - loss 0.60759550\n",
      "2019-01-24 16:31:25,999 epoch 22 - iter 42/72 - loss 0.64680547\n",
      "2019-01-24 16:31:30,286 epoch 22 - iter 49/72 - loss 0.64208387\n",
      "2019-01-24 16:31:34,542 epoch 22 - iter 56/72 - loss 0.63211937\n",
      "2019-01-24 16:31:38,901 epoch 22 - iter 63/72 - loss 0.64969117\n",
      "2019-01-24 16:31:43,030 epoch 22 - iter 70/72 - loss 0.63140273\n",
      "2019-01-24 16:31:43,339 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:31:43,341 EPOCH 22 done: loss 0.6367 - lr 0.1000 - bad epochs 0\n",
      "2019-01-24 16:31:44,774 DEV  : loss 0.38114467 - f-score 0.8879 - acc 0.8879\n",
      "2019-01-24 16:31:51,713 TEST : loss 0.60346901 - f-score 0.8677 - acc 0.8676\n",
      "2019-01-24 16:31:51,716 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:31:52,253 epoch 23 - iter 0/72 - loss 0.47734678\n",
      "2019-01-24 16:31:56,488 epoch 23 - iter 7/72 - loss 0.67789524\n",
      "2019-01-24 16:32:01,258 epoch 23 - iter 14/72 - loss 0.57117895\n",
      "2019-01-24 16:32:05,457 epoch 23 - iter 21/72 - loss 0.60800947\n",
      "2019-01-24 16:32:09,744 epoch 23 - iter 28/72 - loss 0.53663885\n",
      "2019-01-24 16:32:13,966 epoch 23 - iter 35/72 - loss 0.55081246\n",
      "2019-01-24 16:32:18,028 epoch 23 - iter 42/72 - loss 0.56639298\n",
      "2019-01-24 16:32:22,382 epoch 23 - iter 49/72 - loss 0.56929024\n",
      "2019-01-24 16:32:26,884 epoch 23 - iter 56/72 - loss 0.56786013\n",
      "2019-01-24 16:32:31,081 epoch 23 - iter 63/72 - loss 0.57689195\n",
      "2019-01-24 16:32:35,841 epoch 23 - iter 70/72 - loss 0.55661219\n",
      "2019-01-24 16:32:36,097 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:32:36,098 EPOCH 23 done: loss 0.5577 - lr 0.1000 - bad epochs 1\n",
      "2019-01-24 16:32:37,872 DEV  : loss 0.36164135 - f-score 0.8663 - acc 0.8664\n",
      "2019-01-24 16:32:47,086 TEST : loss 0.50509459 - f-score 0.8652 - acc 0.8652\n",
      "2019-01-24 16:32:49,602 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:32:50,390 epoch 24 - iter 0/72 - loss 1.52411032\n",
      "2019-01-24 16:32:54,316 epoch 24 - iter 7/72 - loss 0.53455316\n",
      "2019-01-24 16:32:58,612 epoch 24 - iter 14/72 - loss 0.57529581\n",
      "2019-01-24 16:33:03,019 epoch 24 - iter 21/72 - loss 0.60660941\n",
      "2019-01-24 16:33:07,064 epoch 24 - iter 28/72 - loss 0.61345849\n",
      "2019-01-24 16:33:11,577 epoch 24 - iter 35/72 - loss 0.67121847\n",
      "2019-01-24 16:33:15,595 epoch 24 - iter 42/72 - loss 0.63438085\n",
      "2019-01-24 16:33:19,547 epoch 24 - iter 49/72 - loss 0.60706901\n",
      "2019-01-24 16:33:23,814 epoch 24 - iter 56/72 - loss 0.61749082\n",
      "2019-01-24 16:33:28,180 epoch 24 - iter 63/72 - loss 0.61258535\n",
      "2019-01-24 16:33:32,288 epoch 24 - iter 70/72 - loss 0.61788254\n",
      "2019-01-24 16:33:32,554 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:33:32,556 EPOCH 24 done: loss 0.6163 - lr 0.1000 - bad epochs 0\n",
      "2019-01-24 16:33:34,658 DEV  : loss 0.32788962 - f-score 0.8818 - acc 0.8818\n",
      "2019-01-24 16:33:41,562 TEST : loss 0.49024412 - f-score 0.8735 - acc 0.8735\n",
      "2019-01-24 16:33:41,565 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:33:42,163 epoch 25 - iter 0/72 - loss 0.44372404\n",
      "2019-01-24 16:33:46,749 epoch 25 - iter 7/72 - loss 0.49488557\n",
      "2019-01-24 16:33:51,465 epoch 25 - iter 14/72 - loss 0.46725344\n",
      "2019-01-24 16:33:55,575 epoch 25 - iter 21/72 - loss 0.49269406\n",
      "2019-01-24 16:33:59,805 epoch 25 - iter 28/72 - loss 0.48019751\n",
      "2019-01-24 16:34:04,127 epoch 25 - iter 35/72 - loss 0.52294979\n",
      "2019-01-24 16:34:08,221 epoch 25 - iter 42/72 - loss 0.59699447\n",
      "2019-01-24 16:34:12,352 epoch 25 - iter 49/72 - loss 0.60714134\n",
      "2019-01-24 16:34:16,445 epoch 25 - iter 56/72 - loss 0.61849087\n",
      "2019-01-24 16:34:20,905 epoch 25 - iter 63/72 - loss 0.60737213\n",
      "2019-01-24 16:34:25,281 epoch 25 - iter 70/72 - loss 0.59657630\n",
      "2019-01-24 16:34:25,557 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:34:25,560 EPOCH 25 done: loss 0.5959 - lr 0.1000 - bad epochs 1\n",
      "2019-01-24 16:34:27,340 DEV  : loss 0.30586481 - f-score 0.9018 - acc 0.9018\n",
      "2019-01-24 16:34:34,902 TEST : loss 0.48978344 - f-score 0.8771 - acc 0.8771\n",
      "2019-01-24 16:34:34,905 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:34:35,436 epoch 26 - iter 0/72 - loss 0.56570530\n",
      "2019-01-24 16:34:39,618 epoch 26 - iter 7/72 - loss 0.65514077\n",
      "2019-01-24 16:34:43,957 epoch 26 - iter 14/72 - loss 0.62763405\n",
      "2019-01-24 16:34:48,381 epoch 26 - iter 21/72 - loss 0.69721258\n",
      "2019-01-24 16:34:52,309 epoch 26 - iter 28/72 - loss 0.68508497\n",
      "2019-01-24 16:34:56,499 epoch 26 - iter 35/72 - loss 0.61771862\n",
      "2019-01-24 16:35:00,751 epoch 26 - iter 42/72 - loss 0.59836863\n",
      "2019-01-24 16:35:05,130 epoch 26 - iter 49/72 - loss 0.57152124\n",
      "2019-01-24 16:35:09,405 epoch 26 - iter 56/72 - loss 0.56618573\n",
      "2019-01-24 16:35:13,879 epoch 26 - iter 63/72 - loss 0.58010837\n",
      "2019-01-24 16:35:18,229 epoch 26 - iter 70/72 - loss 0.56049871\n",
      "2019-01-24 16:35:18,452 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:35:18,454 EPOCH 26 done: loss 0.5589 - lr 0.1000 - bad epochs 2\n",
      "2019-01-24 16:35:19,845 DEV  : loss 0.31269521 - f-score 0.9041 - acc 0.9041\n",
      "2019-01-24 16:35:26,818 TEST : loss 0.50754684 - f-score 0.8900 - acc 0.8900\n",
      "2019-01-24 16:35:26,821 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:35:27,344 epoch 27 - iter 0/72 - loss 0.84961468\n",
      "2019-01-24 16:35:31,664 epoch 27 - iter 7/72 - loss 0.61942040\n",
      "2019-01-24 16:35:36,277 epoch 27 - iter 14/72 - loss 0.61763457\n",
      "2019-01-24 16:35:40,341 epoch 27 - iter 21/72 - loss 0.62936715\n",
      "2019-01-24 16:35:44,538 epoch 27 - iter 28/72 - loss 0.54235872\n",
      "2019-01-24 16:35:49,054 epoch 27 - iter 35/72 - loss 0.59580000\n",
      "2019-01-24 16:35:53,031 epoch 27 - iter 42/72 - loss 0.58941330\n",
      "2019-01-24 16:35:57,172 epoch 27 - iter 49/72 - loss 0.55686178\n",
      "2019-01-24 16:36:01,157 epoch 27 - iter 56/72 - loss 0.55118087\n",
      "2019-01-24 16:36:05,324 epoch 27 - iter 63/72 - loss 0.57996291\n",
      "2019-01-24 16:36:09,110 epoch 27 - iter 70/72 - loss 0.60707421\n",
      "2019-01-24 16:36:09,411 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:36:09,413 EPOCH 27 done: loss 0.6072 - lr 0.1000 - bad epochs 3\n",
      "2019-01-24 16:36:10,751 DEV  : loss 0.34741387 - f-score 0.8908 - acc 0.8908\n",
      "2019-01-24 16:36:17,631 TEST : loss 0.51929474 - f-score 0.8847 - acc 0.8847\n",
      "Epoch    26: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2019-01-24 16:36:17,634 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:36:18,209 epoch 28 - iter 0/72 - loss 0.74783564\n",
      "2019-01-24 16:36:22,363 epoch 28 - iter 7/72 - loss 0.48679010\n",
      "2019-01-24 16:36:26,561 epoch 28 - iter 14/72 - loss 0.48389971\n",
      "2019-01-24 16:36:30,849 epoch 28 - iter 21/72 - loss 0.46326101\n",
      "2019-01-24 16:36:35,473 epoch 28 - iter 28/72 - loss 0.47940421\n",
      "2019-01-24 16:36:39,706 epoch 28 - iter 35/72 - loss 0.52841368\n",
      "2019-01-24 16:36:43,867 epoch 28 - iter 42/72 - loss 0.55283030\n",
      "2019-01-24 16:36:48,201 epoch 28 - iter 49/72 - loss 0.55920853\n",
      "2019-01-24 16:36:52,756 epoch 28 - iter 56/72 - loss 0.53457672\n",
      "2019-01-24 16:36:56,741 epoch 28 - iter 63/72 - loss 0.52435043\n",
      "2019-01-24 16:37:00,779 epoch 28 - iter 70/72 - loss 0.52150098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-24 16:37:01,116 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:37:01,118 EPOCH 28 done: loss 0.5227 - lr 0.0500 - bad epochs 0\n",
      "2019-01-24 16:37:02,523 DEV  : loss 0.30552691 - f-score 0.9091 - acc 0.9091\n",
      "2019-01-24 16:37:09,530 TEST : loss 0.47797504 - f-score 0.8854 - acc 0.8854\n",
      "2019-01-24 16:37:12,058 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:37:12,657 epoch 29 - iter 0/72 - loss 0.29982907\n",
      "2019-01-24 16:37:16,708 epoch 29 - iter 7/72 - loss 0.57266298\n",
      "2019-01-24 16:37:20,568 epoch 29 - iter 14/72 - loss 0.54827596\n",
      "2019-01-24 16:37:25,098 epoch 29 - iter 21/72 - loss 0.54624105\n",
      "2019-01-24 16:37:29,128 epoch 29 - iter 28/72 - loss 0.55518501\n",
      "2019-01-24 16:37:33,460 epoch 29 - iter 35/72 - loss 0.53287935\n",
      "2019-01-24 16:37:37,825 epoch 29 - iter 42/72 - loss 0.50998004\n",
      "2019-01-24 16:37:42,415 epoch 29 - iter 49/72 - loss 0.55138865\n",
      "2019-01-24 16:37:47,155 epoch 29 - iter 56/72 - loss 0.56479880\n",
      "2019-01-24 16:37:51,130 epoch 29 - iter 63/72 - loss 0.57065708\n",
      "2019-01-24 16:37:54,976 epoch 29 - iter 70/72 - loss 0.56785271\n",
      "2019-01-24 16:37:55,202 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:37:55,204 EPOCH 29 done: loss 0.5665 - lr 0.0500 - bad epochs 0\n",
      "2019-01-24 16:37:56,596 DEV  : loss 0.28115910 - f-score 0.9099 - acc 0.9099\n",
      "2019-01-24 16:38:04,449 TEST : loss 0.48123744 - f-score 0.8867 - acc 0.8867\n",
      "2019-01-24 16:38:04,451 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:38:05,023 epoch 30 - iter 0/72 - loss 0.37495759\n",
      "2019-01-24 16:38:09,052 epoch 30 - iter 7/72 - loss 0.47462597\n",
      "2019-01-24 16:38:13,261 epoch 30 - iter 14/72 - loss 0.38887509\n",
      "2019-01-24 16:38:17,490 epoch 30 - iter 21/72 - loss 0.38325963\n",
      "2019-01-24 16:38:22,070 epoch 30 - iter 28/72 - loss 0.40780468\n",
      "2019-01-24 16:38:26,164 epoch 30 - iter 35/72 - loss 0.49550113\n",
      "2019-01-24 16:38:30,130 epoch 30 - iter 42/72 - loss 0.48770542\n",
      "2019-01-24 16:38:34,567 epoch 30 - iter 49/72 - loss 0.49183803\n",
      "2019-01-24 16:38:38,790 epoch 30 - iter 56/72 - loss 0.47697739\n",
      "2019-01-24 16:38:42,679 epoch 30 - iter 63/72 - loss 0.46091908\n",
      "2019-01-24 16:38:46,785 epoch 30 - iter 70/72 - loss 0.48244279\n",
      "2019-01-24 16:38:47,002 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:38:47,004 EPOCH 30 done: loss 0.4808 - lr 0.0500 - bad epochs 1\n",
      "2019-01-24 16:38:48,504 DEV  : loss 0.35440823 - f-score 0.8889 - acc 0.8889\n",
      "2019-01-24 16:38:55,989 TEST : loss 0.48379347 - f-score 0.8835 - acc 0.8835\n",
      "2019-01-24 16:38:58,528 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:38:59,176 epoch 31 - iter 0/72 - loss 1.86583602\n",
      "2019-01-24 16:39:03,613 epoch 31 - iter 7/72 - loss 0.72111839\n",
      "2019-01-24 16:39:08,264 epoch 31 - iter 14/72 - loss 0.49495473\n",
      "2019-01-24 16:39:12,144 epoch 31 - iter 21/72 - loss 0.40215676\n",
      "2019-01-24 16:39:16,665 epoch 31 - iter 28/72 - loss 0.42695424\n",
      "2019-01-24 16:39:20,717 epoch 31 - iter 35/72 - loss 0.44582120\n",
      "2019-01-24 16:39:24,732 epoch 31 - iter 42/72 - loss 0.45299910\n",
      "2019-01-24 16:39:28,714 epoch 31 - iter 49/72 - loss 0.47303506\n",
      "2019-01-24 16:39:32,586 epoch 31 - iter 56/72 - loss 0.47087046\n",
      "2019-01-24 16:39:36,766 epoch 31 - iter 63/72 - loss 0.47264225\n",
      "2019-01-24 16:39:40,981 epoch 31 - iter 70/72 - loss 0.48582425\n",
      "2019-01-24 16:39:41,199 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:39:41,201 EPOCH 31 done: loss 0.4854 - lr 0.0500 - bad epochs 0\n",
      "2019-01-24 16:39:42,586 DEV  : loss 0.27984461 - f-score 0.9099 - acc 0.9099\n",
      "2019-01-24 16:39:49,582 TEST : loss 0.45915273 - f-score 0.8904 - acc 0.8904\n",
      "2019-01-24 16:39:49,585 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:39:50,183 epoch 32 - iter 0/72 - loss 0.27286288\n",
      "2019-01-24 16:39:54,376 epoch 32 - iter 7/72 - loss 0.42379487\n",
      "2019-01-24 16:39:58,495 epoch 32 - iter 14/72 - loss 0.37051829\n",
      "2019-01-24 16:40:02,555 epoch 32 - iter 21/72 - loss 0.43204956\n",
      "2019-01-24 16:40:06,570 epoch 32 - iter 28/72 - loss 0.42314214\n",
      "2019-01-24 16:40:10,627 epoch 32 - iter 35/72 - loss 0.43809493\n",
      "2019-01-24 16:40:15,050 epoch 32 - iter 42/72 - loss 0.41797415\n",
      "2019-01-24 16:40:19,406 epoch 32 - iter 49/72 - loss 0.47199491\n",
      "2019-01-24 16:40:24,111 epoch 32 - iter 56/72 - loss 0.46468109\n",
      "2019-01-24 16:40:28,696 epoch 32 - iter 63/72 - loss 0.47221568\n",
      "2019-01-24 16:40:33,037 epoch 32 - iter 70/72 - loss 0.47057949\n",
      "2019-01-24 16:40:33,313 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:40:33,315 EPOCH 32 done: loss 0.4715 - lr 0.0500 - bad epochs 1\n",
      "2019-01-24 16:40:34,689 DEV  : loss 0.27810088 - f-score 0.9196 - acc 0.9196\n",
      "2019-01-24 16:40:41,649 TEST : loss 0.44971311 - f-score 0.8982 - acc 0.8982\n",
      "2019-01-24 16:40:44,176 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:40:44,805 epoch 33 - iter 0/72 - loss 0.73384374\n",
      "2019-01-24 16:40:49,665 epoch 33 - iter 7/72 - loss 0.73674306\n",
      "2019-01-24 16:40:54,210 epoch 33 - iter 14/72 - loss 0.52666794\n",
      "2019-01-24 16:40:58,378 epoch 33 - iter 21/72 - loss 0.57311253\n",
      "2019-01-24 16:41:02,890 epoch 33 - iter 28/72 - loss 0.51998878\n",
      "2019-01-24 16:41:07,286 epoch 33 - iter 35/72 - loss 0.52349029\n",
      "2019-01-24 16:41:11,536 epoch 33 - iter 42/72 - loss 0.53815987\n",
      "2019-01-24 16:41:15,775 epoch 33 - iter 49/72 - loss 0.54119375\n",
      "2019-01-24 16:41:19,866 epoch 33 - iter 56/72 - loss 0.53512776\n",
      "2019-01-24 16:41:23,777 epoch 33 - iter 63/72 - loss 0.51418390\n",
      "2019-01-24 16:41:28,117 epoch 33 - iter 70/72 - loss 0.49505249\n",
      "2019-01-24 16:41:28,355 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:41:28,357 EPOCH 33 done: loss 0.4940 - lr 0.0500 - bad epochs 0\n",
      "2019-01-24 16:41:29,733 DEV  : loss 0.27046418 - f-score 0.9091 - acc 0.9091\n",
      "2019-01-24 16:41:36,632 TEST : loss 0.46667475 - f-score 0.8942 - acc 0.8942\n",
      "2019-01-24 16:41:36,634 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:41:37,219 epoch 34 - iter 0/72 - loss 0.06271255\n",
      "2019-01-24 16:41:41,059 epoch 34 - iter 7/72 - loss 0.23825800\n",
      "2019-01-24 16:41:45,412 epoch 34 - iter 14/72 - loss 0.47874982\n",
      "2019-01-24 16:41:49,577 epoch 34 - iter 21/72 - loss 0.51456582\n",
      "2019-01-24 16:41:53,600 epoch 34 - iter 28/72 - loss 0.50420330\n",
      "2019-01-24 16:41:57,690 epoch 34 - iter 35/72 - loss 0.48676363\n",
      "2019-01-24 16:42:02,174 epoch 34 - iter 42/72 - loss 0.53172645\n",
      "2019-01-24 16:42:06,388 epoch 34 - iter 49/72 - loss 0.52140015\n",
      "2019-01-24 16:42:11,045 epoch 34 - iter 56/72 - loss 0.49362224\n",
      "2019-01-24 16:42:15,293 epoch 34 - iter 63/72 - loss 0.47731528\n",
      "2019-01-24 16:42:19,176 epoch 34 - iter 70/72 - loss 0.46415046\n",
      "2019-01-24 16:42:19,442 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:42:19,444 EPOCH 34 done: loss 0.4628 - lr 0.0500 - bad epochs 1\n",
      "2019-01-24 16:42:20,799 DEV  : loss 0.29925609 - f-score 0.9041 - acc 0.9041\n",
      "2019-01-24 16:42:28,007 TEST : loss 0.45322424 - f-score 0.9045 - acc 0.9046\n",
      "2019-01-24 16:42:30,538 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:42:31,167 epoch 35 - iter 0/72 - loss 0.90843207\n",
      "2019-01-24 16:42:35,752 epoch 35 - iter 7/72 - loss 0.51628374\n",
      "2019-01-24 16:42:39,604 epoch 35 - iter 14/72 - loss 0.55875001\n",
      "2019-01-24 16:42:43,503 epoch 35 - iter 21/72 - loss 0.52563679\n",
      "2019-01-24 16:42:47,760 epoch 35 - iter 28/72 - loss 0.49390463\n",
      "2019-01-24 16:42:52,321 epoch 35 - iter 35/72 - loss 0.50279032\n",
      "2019-01-24 16:42:56,764 epoch 35 - iter 42/72 - loss 0.49594230\n",
      "2019-01-24 16:43:01,224 epoch 35 - iter 49/72 - loss 0.49381832\n",
      "2019-01-24 16:43:05,380 epoch 35 - iter 56/72 - loss 0.49352997\n",
      "2019-01-24 16:43:09,443 epoch 35 - iter 63/72 - loss 0.48748851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-24 16:43:13,459 epoch 35 - iter 70/72 - loss 0.48142583\n",
      "2019-01-24 16:43:13,663 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:43:13,665 EPOCH 35 done: loss 0.4797 - lr 0.0500 - bad epochs 0\n",
      "2019-01-24 16:43:15,867 DEV  : loss 0.28934842 - f-score 0.9140 - acc 0.9140\n",
      "2019-01-24 16:43:22,856 TEST : loss 0.44931513 - f-score 0.8942 - acc 0.8942\n",
      "2019-01-24 16:43:22,859 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:43:23,633 epoch 36 - iter 0/72 - loss 0.31556296\n",
      "2019-01-24 16:43:27,672 epoch 36 - iter 7/72 - loss 0.52676317\n",
      "2019-01-24 16:43:31,918 epoch 36 - iter 14/72 - loss 0.54779896\n",
      "2019-01-24 16:43:36,234 epoch 36 - iter 21/72 - loss 0.51412926\n",
      "2019-01-24 16:43:40,757 epoch 36 - iter 28/72 - loss 0.51040930\n",
      "2019-01-24 16:43:45,337 epoch 36 - iter 35/72 - loss 0.47443133\n",
      "2019-01-24 16:43:49,408 epoch 36 - iter 42/72 - loss 0.46629853\n",
      "2019-01-24 16:43:53,436 epoch 36 - iter 49/72 - loss 0.45589031\n",
      "2019-01-24 16:43:57,805 epoch 36 - iter 56/72 - loss 0.46805873\n",
      "2019-01-24 16:44:02,136 epoch 36 - iter 63/72 - loss 0.44576307\n",
      "2019-01-24 16:44:06,331 epoch 36 - iter 70/72 - loss 0.44638134\n",
      "2019-01-24 16:44:06,582 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:44:06,584 EPOCH 36 done: loss 0.4458 - lr 0.0500 - bad epochs 1\n",
      "2019-01-24 16:44:08,156 DEV  : loss 0.28967351 - f-score 0.8850 - acc 0.8850\n",
      "2019-01-24 16:44:15,500 TEST : loss 0.45133922 - f-score 0.8920 - acc 0.8920\n",
      "2019-01-24 16:44:18,040 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:44:18,673 epoch 37 - iter 0/72 - loss 0.10310107\n",
      "2019-01-24 16:44:22,824 epoch 37 - iter 7/72 - loss 0.16356058\n",
      "2019-01-24 16:44:27,378 epoch 37 - iter 14/72 - loss 0.29916545\n",
      "2019-01-24 16:44:31,545 epoch 37 - iter 21/72 - loss 0.30829446\n",
      "2019-01-24 16:44:35,974 epoch 37 - iter 28/72 - loss 0.36372310\n",
      "2019-01-24 16:44:40,674 epoch 37 - iter 35/72 - loss 0.40059925\n",
      "2019-01-24 16:44:45,046 epoch 37 - iter 42/72 - loss 0.38846024\n",
      "2019-01-24 16:44:48,818 epoch 37 - iter 49/72 - loss 0.41475519\n",
      "2019-01-24 16:44:53,121 epoch 37 - iter 56/72 - loss 0.44314805\n",
      "2019-01-24 16:44:57,257 epoch 37 - iter 63/72 - loss 0.42850123\n",
      "2019-01-24 16:45:01,685 epoch 37 - iter 70/72 - loss 0.44671821\n",
      "2019-01-24 16:45:02,009 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:45:02,010 EPOCH 37 done: loss 0.4471 - lr 0.0500 - bad epochs 0\n",
      "2019-01-24 16:45:03,390 DEV  : loss 0.27930382 - f-score 0.9099 - acc 0.9099\n",
      "2019-01-24 16:45:10,224 TEST : loss 0.47440320 - f-score 0.8898 - acc 0.8898\n",
      "2019-01-24 16:45:10,227 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:45:10,893 epoch 38 - iter 0/72 - loss 0.80194664\n",
      "2019-01-24 16:45:15,008 epoch 38 - iter 7/72 - loss 0.47836497\n",
      "2019-01-24 16:45:18,981 epoch 38 - iter 14/72 - loss 0.43548062\n",
      "2019-01-24 16:45:22,907 epoch 38 - iter 21/72 - loss 0.47671795\n",
      "2019-01-24 16:45:27,423 epoch 38 - iter 28/72 - loss 0.42242517\n",
      "2019-01-24 16:45:31,470 epoch 38 - iter 35/72 - loss 0.46403602\n",
      "2019-01-24 16:45:35,616 epoch 38 - iter 42/72 - loss 0.42724546\n",
      "2019-01-24 16:45:39,875 epoch 38 - iter 49/72 - loss 0.43407892\n",
      "2019-01-24 16:45:44,144 epoch 38 - iter 56/72 - loss 0.44600069\n",
      "2019-01-24 16:45:48,192 epoch 38 - iter 63/72 - loss 0.46132006\n",
      "2019-01-24 16:45:52,142 epoch 38 - iter 70/72 - loss 0.46120145\n",
      "2019-01-24 16:45:52,372 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:45:52,374 EPOCH 38 done: loss 0.4607 - lr 0.0500 - bad epochs 1\n",
      "2019-01-24 16:45:53,758 DEV  : loss 0.27134186 - f-score 0.9140 - acc 0.9140\n",
      "2019-01-24 16:46:00,821 TEST : loss 0.44964281 - f-score 0.9069 - acc 0.9068\n",
      "2019-01-24 16:46:00,825 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:46:01,395 epoch 39 - iter 0/72 - loss 0.25839424\n",
      "2019-01-24 16:46:05,783 epoch 39 - iter 7/72 - loss 0.38697779\n",
      "2019-01-24 16:46:09,973 epoch 39 - iter 14/72 - loss 0.44254324\n",
      "2019-01-24 16:46:13,923 epoch 39 - iter 21/72 - loss 0.40938481\n",
      "2019-01-24 16:46:18,271 epoch 39 - iter 28/72 - loss 0.38411638\n",
      "2019-01-24 16:46:22,659 epoch 39 - iter 35/72 - loss 0.37163616\n",
      "2019-01-24 16:46:26,923 epoch 39 - iter 42/72 - loss 0.39357797\n",
      "2019-01-24 16:46:31,264 epoch 39 - iter 49/72 - loss 0.42321068\n",
      "2019-01-24 16:46:36,011 epoch 39 - iter 56/72 - loss 0.43412725\n",
      "2019-01-24 16:46:40,136 epoch 39 - iter 63/72 - loss 0.44983000\n",
      "2019-01-24 16:46:44,494 epoch 39 - iter 70/72 - loss 0.46056693\n",
      "2019-01-24 16:46:44,743 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:46:44,744 EPOCH 39 done: loss 0.4588 - lr 0.0500 - bad epochs 2\n",
      "2019-01-24 16:46:46,141 DEV  : loss 0.26097775 - f-score 0.9140 - acc 0.9140\n",
      "2019-01-24 16:46:53,055 TEST : loss 0.44145831 - f-score 0.9103 - acc 0.9103\n",
      "2019-01-24 16:46:53,058 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:46:53,606 epoch 40 - iter 0/72 - loss 0.21382856\n",
      "2019-01-24 16:46:58,130 epoch 40 - iter 7/72 - loss 0.44669753\n",
      "2019-01-24 16:47:02,282 epoch 40 - iter 14/72 - loss 0.45921476\n",
      "2019-01-24 16:47:06,104 epoch 40 - iter 21/72 - loss 0.40330389\n",
      "2019-01-24 16:47:10,188 epoch 40 - iter 28/72 - loss 0.39738082\n",
      "2019-01-24 16:47:14,639 epoch 40 - iter 35/72 - loss 0.39459191\n",
      "2019-01-24 16:47:18,815 epoch 40 - iter 42/72 - loss 0.42901702\n",
      "2019-01-24 16:47:23,102 epoch 40 - iter 49/72 - loss 0.45197679\n",
      "2019-01-24 16:47:27,099 epoch 40 - iter 56/72 - loss 0.42395062\n",
      "2019-01-24 16:47:31,227 epoch 40 - iter 63/72 - loss 0.43455153\n",
      "2019-01-24 16:47:35,420 epoch 40 - iter 70/72 - loss 0.43764277\n",
      "2019-01-24 16:47:35,688 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:47:35,689 EPOCH 40 done: loss 0.4488 - lr 0.0500 - bad epochs 3\n",
      "2019-01-24 16:47:37,031 DEV  : loss 0.27206078 - f-score 0.9099 - acc 0.9099\n",
      "2019-01-24 16:47:44,737 TEST : loss 0.45988059 - f-score 0.9013 - acc 0.9013\n",
      "Epoch    39: reducing learning rate of group 0 to 2.5000e-02.\n",
      "2019-01-24 16:47:44,739 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:47:45,297 epoch 41 - iter 0/72 - loss 1.17930734\n",
      "2019-01-24 16:47:49,464 epoch 41 - iter 7/72 - loss 0.41395914\n",
      "2019-01-24 16:47:53,738 epoch 41 - iter 14/72 - loss 0.43171956\n",
      "2019-01-24 16:47:58,380 epoch 41 - iter 21/72 - loss 0.44023599\n",
      "2019-01-24 16:48:02,985 epoch 41 - iter 28/72 - loss 0.44041855\n",
      "2019-01-24 16:48:06,989 epoch 41 - iter 35/72 - loss 0.40802860\n",
      "2019-01-24 16:48:11,282 epoch 41 - iter 42/72 - loss 0.40871671\n",
      "2019-01-24 16:48:16,084 epoch 41 - iter 49/72 - loss 0.44299838\n",
      "2019-01-24 16:48:20,429 epoch 41 - iter 56/72 - loss 0.43537736\n",
      "2019-01-24 16:48:24,287 epoch 41 - iter 63/72 - loss 0.45202794\n",
      "2019-01-24 16:48:28,211 epoch 41 - iter 70/72 - loss 0.45908922\n",
      "2019-01-24 16:48:28,456 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:48:28,457 EPOCH 41 done: loss 0.4576 - lr 0.0250 - bad epochs 0\n",
      "2019-01-24 16:48:29,871 DEV  : loss 0.28879455 - f-score 0.9041 - acc 0.9041\n",
      "2019-01-24 16:48:36,846 TEST : loss 0.44283000 - f-score 0.8993 - acc 0.8993\n",
      "2019-01-24 16:48:36,848 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:48:37,500 epoch 42 - iter 0/72 - loss 0.58090937\n",
      "2019-01-24 16:48:41,383 epoch 42 - iter 7/72 - loss 0.46453591\n",
      "2019-01-24 16:48:45,399 epoch 42 - iter 14/72 - loss 0.44349635\n",
      "2019-01-24 16:48:49,661 epoch 42 - iter 21/72 - loss 0.40349940\n",
      "2019-01-24 16:48:54,034 epoch 42 - iter 28/72 - loss 0.41296024\n",
      "2019-01-24 16:48:58,110 epoch 42 - iter 35/72 - loss 0.43088927\n",
      "2019-01-24 16:49:02,308 epoch 42 - iter 42/72 - loss 0.41287308\n",
      "2019-01-24 16:49:06,248 epoch 42 - iter 49/72 - loss 0.46466629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-24 16:49:10,204 epoch 42 - iter 56/72 - loss 0.45162348\n",
      "2019-01-24 16:49:14,260 epoch 42 - iter 63/72 - loss 0.46862025\n",
      "2019-01-24 16:49:18,359 epoch 42 - iter 70/72 - loss 0.45705698\n",
      "2019-01-24 16:49:18,615 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:49:18,617 EPOCH 42 done: loss 0.4554 - lr 0.0250 - bad epochs 1\n",
      "2019-01-24 16:49:20,149 DEV  : loss 0.28857079 - f-score 0.9091 - acc 0.9091\n",
      "2019-01-24 16:49:27,193 TEST : loss 0.44788691 - f-score 0.9038 - acc 0.9038\n",
      "2019-01-24 16:49:27,196 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:49:27,798 epoch 43 - iter 0/72 - loss 0.11482526\n",
      "2019-01-24 16:49:31,977 epoch 43 - iter 7/72 - loss 0.49107690\n",
      "2019-01-24 16:49:36,156 epoch 43 - iter 14/72 - loss 0.41326642\n",
      "2019-01-24 16:49:40,474 epoch 43 - iter 21/72 - loss 0.41375193\n",
      "2019-01-24 16:49:44,665 epoch 43 - iter 28/72 - loss 0.45642078\n",
      "2019-01-24 16:49:48,884 epoch 43 - iter 35/72 - loss 0.42481816\n",
      "2019-01-24 16:49:53,759 epoch 43 - iter 42/72 - loss 0.39423698\n",
      "2019-01-24 16:49:57,998 epoch 43 - iter 49/72 - loss 0.40625743\n",
      "2019-01-24 16:50:02,130 epoch 43 - iter 56/72 - loss 0.41070166\n",
      "2019-01-24 16:50:06,491 epoch 43 - iter 63/72 - loss 0.40778030\n",
      "2019-01-24 16:50:10,883 epoch 43 - iter 70/72 - loss 0.39115583\n",
      "2019-01-24 16:50:11,075 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:50:11,077 EPOCH 43 done: loss 0.3901 - lr 0.0250 - bad epochs 2\n",
      "2019-01-24 16:50:12,520 DEV  : loss 0.26586077 - f-score 0.9099 - acc 0.9099\n",
      "2019-01-24 16:50:19,470 TEST : loss 0.44458485 - f-score 0.9098 - acc 0.9098\n",
      "2019-01-24 16:50:22,000 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:50:22,648 epoch 44 - iter 0/72 - loss 1.14648795\n",
      "2019-01-24 16:50:26,830 epoch 44 - iter 7/72 - loss 0.58402555\n",
      "2019-01-24 16:50:31,015 epoch 44 - iter 14/72 - loss 0.48411846\n",
      "2019-01-24 16:50:35,564 epoch 44 - iter 21/72 - loss 0.43670738\n",
      "2019-01-24 16:50:39,759 epoch 44 - iter 28/72 - loss 0.43843921\n",
      "2019-01-24 16:50:44,154 epoch 44 - iter 35/72 - loss 0.45102924\n",
      "2019-01-24 16:50:48,730 epoch 44 - iter 42/72 - loss 0.42596060\n",
      "2019-01-24 16:50:52,560 epoch 44 - iter 49/72 - loss 0.41999687\n",
      "2019-01-24 16:50:56,544 epoch 44 - iter 56/72 - loss 0.41804287\n",
      "2019-01-24 16:51:00,869 epoch 44 - iter 63/72 - loss 0.40894659\n",
      "2019-01-24 16:51:05,185 epoch 44 - iter 70/72 - loss 0.40021102\n",
      "2019-01-24 16:51:05,445 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:51:05,447 EPOCH 44 done: loss 0.3999 - lr 0.0250 - bad epochs 0\n",
      "2019-01-24 16:51:06,811 DEV  : loss 0.27604574 - f-score 0.9058 - acc 0.9058\n",
      "2019-01-24 16:51:13,677 TEST : loss 0.44087639 - f-score 0.9046 - acc 0.9046\n",
      "2019-01-24 16:51:13,680 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:51:14,250 epoch 45 - iter 0/72 - loss 0.38489807\n",
      "2019-01-24 16:51:18,340 epoch 45 - iter 7/72 - loss 0.19978901\n",
      "2019-01-24 16:51:22,517 epoch 45 - iter 14/72 - loss 0.29638664\n",
      "2019-01-24 16:51:26,804 epoch 45 - iter 21/72 - loss 0.31445227\n",
      "2019-01-24 16:51:30,743 epoch 45 - iter 28/72 - loss 0.31112497\n",
      "2019-01-24 16:51:35,075 epoch 45 - iter 35/72 - loss 0.32806748\n",
      "2019-01-24 16:51:39,956 epoch 45 - iter 42/72 - loss 0.41812757\n",
      "2019-01-24 16:51:44,455 epoch 45 - iter 49/72 - loss 0.39968910\n",
      "2019-01-24 16:51:48,808 epoch 45 - iter 56/72 - loss 0.40002426\n",
      "2019-01-24 16:51:52,900 epoch 45 - iter 63/72 - loss 0.39077828\n",
      "2019-01-24 16:51:57,467 epoch 45 - iter 70/72 - loss 0.41605124\n",
      "2019-01-24 16:51:57,716 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:51:57,718 EPOCH 45 done: loss 0.4147 - lr 0.0250 - bad epochs 1\n",
      "2019-01-24 16:51:59,188 DEV  : loss 0.27049255 - f-score 0.9140 - acc 0.9140\n",
      "2019-01-24 16:52:06,500 TEST : loss 0.43885174 - f-score 0.9052 - acc 0.9052\n",
      "2019-01-24 16:52:06,503 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:52:07,177 epoch 46 - iter 0/72 - loss 0.95188892\n",
      "2019-01-24 16:52:11,790 epoch 46 - iter 7/72 - loss 0.60879542\n",
      "2019-01-24 16:52:16,484 epoch 46 - iter 14/72 - loss 0.46741847\n",
      "2019-01-24 16:52:20,941 epoch 46 - iter 21/72 - loss 0.41167252\n",
      "2019-01-24 16:52:25,441 epoch 46 - iter 28/72 - loss 0.39468629\n",
      "2019-01-24 16:52:30,003 epoch 46 - iter 35/72 - loss 0.40953764\n",
      "2019-01-24 16:52:34,583 epoch 46 - iter 42/72 - loss 0.39466650\n",
      "2019-01-24 16:52:38,888 epoch 46 - iter 49/72 - loss 0.38514116\n",
      "2019-01-24 16:52:43,613 epoch 46 - iter 56/72 - loss 0.38678783\n",
      "2019-01-24 16:52:48,032 epoch 46 - iter 63/72 - loss 0.40815777\n",
      "2019-01-24 16:52:52,268 epoch 46 - iter 70/72 - loss 0.40393167\n",
      "2019-01-24 16:52:52,519 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:52:52,521 EPOCH 46 done: loss 0.4028 - lr 0.0250 - bad epochs 2\n",
      "2019-01-24 16:52:54,836 DEV  : loss 0.27821314 - f-score 0.9140 - acc 0.9140\n",
      "2019-01-24 16:53:01,875 TEST : loss 0.44950181 - f-score 0.8998 - acc 0.8998\n",
      "2019-01-24 16:53:01,878 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:53:02,506 epoch 47 - iter 0/72 - loss 0.48231637\n",
      "2019-01-24 16:53:07,108 epoch 47 - iter 7/72 - loss 0.56896715\n",
      "2019-01-24 16:53:11,116 epoch 47 - iter 14/72 - loss 0.40917793\n",
      "2019-01-24 16:53:15,626 epoch 47 - iter 21/72 - loss 0.40485810\n",
      "2019-01-24 16:53:20,177 epoch 47 - iter 28/72 - loss 0.48280968\n",
      "2019-01-24 16:53:24,204 epoch 47 - iter 35/72 - loss 0.45249617\n",
      "2019-01-24 16:53:28,298 epoch 47 - iter 42/72 - loss 0.44507367\n",
      "2019-01-24 16:53:32,719 epoch 47 - iter 49/72 - loss 0.42843766\n",
      "2019-01-24 16:53:36,836 epoch 47 - iter 56/72 - loss 0.41987607\n",
      "2019-01-24 16:53:41,251 epoch 47 - iter 63/72 - loss 0.39993360\n",
      "2019-01-24 16:53:45,738 epoch 47 - iter 70/72 - loss 0.38409171\n",
      "2019-01-24 16:53:45,972 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:53:45,975 EPOCH 47 done: loss 0.3827 - lr 0.0250 - bad epochs 3\n",
      "2019-01-24 16:53:47,347 DEV  : loss 0.28250280 - f-score 0.9091 - acc 0.9091\n",
      "2019-01-24 16:53:54,261 TEST : loss 0.44498637 - f-score 0.9058 - acc 0.9058\n",
      "2019-01-24 16:53:56,799 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:53:57,430 epoch 48 - iter 0/72 - loss 0.33396441\n",
      "2019-01-24 16:54:01,844 epoch 48 - iter 7/72 - loss 0.47043198\n",
      "2019-01-24 16:54:06,316 epoch 48 - iter 14/72 - loss 0.36795556\n",
      "2019-01-24 16:54:10,938 epoch 48 - iter 21/72 - loss 0.39430024\n",
      "2019-01-24 16:54:15,115 epoch 48 - iter 28/72 - loss 0.46587531\n",
      "2019-01-24 16:54:19,650 epoch 48 - iter 35/72 - loss 0.45021049\n",
      "2019-01-24 16:54:24,115 epoch 48 - iter 42/72 - loss 0.41735261\n",
      "2019-01-24 16:54:28,167 epoch 48 - iter 49/72 - loss 0.40525973\n",
      "2019-01-24 16:54:32,597 epoch 48 - iter 56/72 - loss 0.42547702\n",
      "2019-01-24 16:54:36,676 epoch 48 - iter 63/72 - loss 0.42258852\n",
      "2019-01-24 16:54:40,613 epoch 48 - iter 70/72 - loss 0.41100414\n",
      "2019-01-24 16:54:40,868 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:54:40,870 EPOCH 48 done: loss 0.4147 - lr 0.0250 - bad epochs 0\n",
      "2019-01-24 16:54:42,213 DEV  : loss 0.28002068 - f-score 0.9140 - acc 0.9140\n",
      "2019-01-24 16:54:49,253 TEST : loss 0.45200908 - f-score 0.9045 - acc 0.9046\n",
      "2019-01-24 16:54:49,255 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:54:49,894 epoch 49 - iter 0/72 - loss 0.12978065\n",
      "2019-01-24 16:54:54,082 epoch 49 - iter 7/72 - loss 0.22502398\n",
      "2019-01-24 16:54:58,459 epoch 49 - iter 14/72 - loss 0.22061932\n",
      "2019-01-24 16:55:02,925 epoch 49 - iter 21/72 - loss 0.33405817\n",
      "2019-01-24 16:55:07,222 epoch 49 - iter 28/72 - loss 0.46308230\n",
      "2019-01-24 16:55:11,365 epoch 49 - iter 35/72 - loss 0.44087568\n",
      "2019-01-24 16:55:15,667 epoch 49 - iter 42/72 - loss 0.40420087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-24 16:55:19,616 epoch 49 - iter 49/72 - loss 0.40223268\n",
      "2019-01-24 16:55:24,158 epoch 49 - iter 56/72 - loss 0.39863811\n",
      "2019-01-24 16:55:34,780 epoch 49 - iter 63/72 - loss 0.39213583\n",
      "2019-01-24 16:55:39,837 epoch 49 - iter 70/72 - loss 0.39519401\n",
      "2019-01-24 16:55:40,133 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:55:40,138 EPOCH 49 done: loss 0.3973 - lr 0.0250 - bad epochs 1\n",
      "2019-01-24 16:55:41,770 DEV  : loss 0.27073297 - f-score 0.9140 - acc 0.9140\n",
      "2019-01-24 16:55:49,875 TEST : loss 0.44106990 - f-score 0.9050 - acc 0.9050\n",
      "2019-01-24 16:55:49,880 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:55:50,592 epoch 50 - iter 0/72 - loss 0.17908531\n",
      "2019-01-24 16:55:55,368 epoch 50 - iter 7/72 - loss 0.37646872\n",
      "2019-01-24 16:56:00,133 epoch 50 - iter 14/72 - loss 0.36837279\n",
      "2019-01-24 16:56:05,134 epoch 50 - iter 21/72 - loss 0.35649987\n",
      "2019-01-24 16:56:09,560 epoch 50 - iter 28/72 - loss 0.36507807\n",
      "2019-01-24 16:56:13,928 epoch 50 - iter 35/72 - loss 0.40228924\n",
      "2019-01-24 16:56:18,554 epoch 50 - iter 42/72 - loss 0.41992363\n",
      "2019-01-24 16:56:22,956 epoch 50 - iter 49/72 - loss 0.41239205\n",
      "2019-01-24 16:56:27,374 epoch 50 - iter 56/72 - loss 0.40289482\n",
      "2019-01-24 16:56:32,125 epoch 50 - iter 63/72 - loss 0.39229895\n",
      "2019-01-24 16:56:36,468 epoch 50 - iter 70/72 - loss 0.39088320\n",
      "2019-01-24 16:56:36,686 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:56:36,688 EPOCH 50 done: loss 0.3913 - lr 0.0250 - bad epochs 2\n",
      "2019-01-24 16:56:38,197 DEV  : loss 0.25640020 - f-score 0.9140 - acc 0.9140\n",
      "2019-01-24 16:56:46,721 TEST : loss 0.43696934 - f-score 0.9099 - acc 0.9098\n",
      "2019-01-24 16:56:46,724 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:56:47,360 epoch 51 - iter 0/72 - loss 0.94658434\n",
      "2019-01-24 16:56:51,996 epoch 51 - iter 7/72 - loss 0.52217524\n",
      "2019-01-24 16:56:56,469 epoch 51 - iter 14/72 - loss 0.47269238\n",
      "2019-01-24 16:57:01,376 epoch 51 - iter 21/72 - loss 0.46923443\n",
      "2019-01-24 16:57:05,832 epoch 51 - iter 28/72 - loss 0.43845635\n",
      "2019-01-24 16:57:10,334 epoch 51 - iter 35/72 - loss 0.45107901\n",
      "2019-01-24 16:57:14,550 epoch 51 - iter 42/72 - loss 0.42300570\n",
      "2019-01-24 16:57:19,128 epoch 51 - iter 49/72 - loss 0.40083960\n",
      "2019-01-24 16:57:23,661 epoch 51 - iter 56/72 - loss 0.38772679\n",
      "2019-01-24 16:57:28,279 epoch 51 - iter 63/72 - loss 0.37879264\n",
      "2019-01-24 16:57:32,761 epoch 51 - iter 70/72 - loss 0.36592830\n",
      "2019-01-24 16:57:33,063 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:57:33,065 EPOCH 51 done: loss 0.3648 - lr 0.0250 - bad epochs 3\n",
      "2019-01-24 16:57:34,973 DEV  : loss 0.26838675 - f-score 0.9140 - acc 0.9140\n",
      "2019-01-24 16:57:44,939 TEST : loss 0.43977159 - f-score 0.9069 - acc 0.9068\n",
      "2019-01-24 16:57:47,592 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:57:48,274 epoch 52 - iter 0/72 - loss 0.04306602\n",
      "2019-01-24 16:57:53,066 epoch 52 - iter 7/72 - loss 0.19236976\n",
      "2019-01-24 16:57:57,789 epoch 52 - iter 14/72 - loss 0.22612662\n",
      "2019-01-24 16:58:02,555 epoch 52 - iter 21/72 - loss 0.24753162\n",
      "2019-01-24 16:58:07,168 epoch 52 - iter 28/72 - loss 0.28869705\n",
      "2019-01-24 16:58:11,761 epoch 52 - iter 35/72 - loss 0.31264734\n",
      "2019-01-24 16:58:16,332 epoch 52 - iter 42/72 - loss 0.33433170\n",
      "2019-01-24 16:58:20,634 epoch 52 - iter 49/72 - loss 0.32194732\n",
      "2019-01-24 16:58:25,277 epoch 52 - iter 56/72 - loss 0.36201812\n",
      "2019-01-24 16:58:29,711 epoch 52 - iter 63/72 - loss 0.36258646\n",
      "2019-01-24 16:58:34,506 epoch 52 - iter 70/72 - loss 0.37549396\n",
      "2019-01-24 16:58:34,862 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:58:34,864 EPOCH 52 done: loss 0.3743 - lr 0.0250 - bad epochs 0\n",
      "2019-01-24 16:58:36,413 DEV  : loss 0.25774506 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 16:58:44,200 TEST : loss 0.42488876 - f-score 0.9070 - acc 0.9070\n",
      "2019-01-24 16:58:44,203 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:58:44,925 epoch 53 - iter 0/72 - loss 0.80746990\n",
      "2019-01-24 16:58:49,248 epoch 53 - iter 7/72 - loss 0.31518852\n",
      "2019-01-24 16:58:53,943 epoch 53 - iter 14/72 - loss 0.27926264\n",
      "2019-01-24 16:58:58,702 epoch 53 - iter 21/72 - loss 0.33937399\n",
      "2019-01-24 16:59:03,369 epoch 53 - iter 28/72 - loss 0.30958923\n",
      "2019-01-24 16:59:08,737 epoch 53 - iter 35/72 - loss 0.36207519\n",
      "2019-01-24 16:59:13,555 epoch 53 - iter 42/72 - loss 0.36597789\n",
      "2019-01-24 16:59:18,041 epoch 53 - iter 49/72 - loss 0.37572094\n",
      "2019-01-24 16:59:22,466 epoch 53 - iter 56/72 - loss 0.37666625\n",
      "2019-01-24 16:59:27,237 epoch 53 - iter 63/72 - loss 0.37735779\n",
      "2019-01-24 16:59:32,081 epoch 53 - iter 70/72 - loss 0.37959009\n",
      "2019-01-24 16:59:32,398 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:59:32,399 EPOCH 53 done: loss 0.3783 - lr 0.0250 - bad epochs 1\n",
      "2019-01-24 16:59:34,026 DEV  : loss 0.26685458 - f-score 0.9140 - acc 0.9140\n",
      "2019-01-24 16:59:41,660 TEST : loss 0.43092072 - f-score 0.9069 - acc 0.9068\n",
      "2019-01-24 16:59:41,663 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 16:59:42,239 epoch 54 - iter 0/72 - loss 0.05028498\n",
      "2019-01-24 16:59:46,707 epoch 54 - iter 7/72 - loss 0.37219007\n",
      "2019-01-24 16:59:51,664 epoch 54 - iter 14/72 - loss 0.32829673\n",
      "2019-01-24 16:59:56,205 epoch 54 - iter 21/72 - loss 0.34212651\n",
      "2019-01-24 17:00:00,731 epoch 54 - iter 28/72 - loss 0.38794943\n",
      "2019-01-24 17:00:05,646 epoch 54 - iter 35/72 - loss 0.37972672\n",
      "2019-01-24 17:00:10,417 epoch 54 - iter 42/72 - loss 0.37771139\n",
      "2019-01-24 17:00:14,835 epoch 54 - iter 49/72 - loss 0.36437671\n",
      "2019-01-24 17:00:19,277 epoch 54 - iter 56/72 - loss 0.38537547\n",
      "2019-01-24 17:00:23,991 epoch 54 - iter 63/72 - loss 0.38896165\n",
      "2019-01-24 17:00:28,597 epoch 54 - iter 70/72 - loss 0.37244857\n",
      "2019-01-24 17:00:28,972 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:00:28,974 EPOCH 54 done: loss 0.3733 - lr 0.0250 - bad epochs 2\n",
      "2019-01-24 17:00:30,556 DEV  : loss 0.27068952 - f-score 0.9133 - acc 0.9132\n",
      "2019-01-24 17:00:38,751 TEST : loss 0.42937005 - f-score 0.9054 - acc 0.9053\n",
      "2019-01-24 17:00:38,754 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:00:39,450 epoch 55 - iter 0/72 - loss 0.45467198\n",
      "2019-01-24 17:00:44,433 epoch 55 - iter 7/72 - loss 0.27562554\n",
      "2019-01-24 17:00:48,671 epoch 55 - iter 14/72 - loss 0.25764038\n",
      "2019-01-24 17:00:53,462 epoch 55 - iter 21/72 - loss 0.27129137\n",
      "2019-01-24 17:00:58,002 epoch 55 - iter 28/72 - loss 0.30588565\n",
      "2019-01-24 17:01:02,931 epoch 55 - iter 35/72 - loss 0.34327905\n",
      "2019-01-24 17:01:07,474 epoch 55 - iter 42/72 - loss 0.35059206\n",
      "2019-01-24 17:01:12,333 epoch 55 - iter 49/72 - loss 0.36240081\n",
      "2019-01-24 17:01:16,606 epoch 55 - iter 56/72 - loss 0.37356059\n",
      "2019-01-24 17:01:20,964 epoch 55 - iter 63/72 - loss 0.36907664\n",
      "2019-01-24 17:01:25,652 epoch 55 - iter 70/72 - loss 0.36873552\n",
      "2019-01-24 17:01:25,983 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:01:25,984 EPOCH 55 done: loss 0.3676 - lr 0.0250 - bad epochs 3\n",
      "2019-01-24 17:01:27,399 DEV  : loss 0.27479869 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:01:35,231 TEST : loss 0.43643007 - f-score 0.9175 - acc 0.9175\n",
      "Epoch    54: reducing learning rate of group 0 to 1.2500e-02.\n",
      "2019-01-24 17:01:35,234 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:01:35,877 epoch 56 - iter 0/72 - loss 0.03862107\n",
      "2019-01-24 17:01:40,713 epoch 56 - iter 7/72 - loss 0.35170152\n",
      "2019-01-24 17:01:45,248 epoch 56 - iter 14/72 - loss 0.31778097\n",
      "2019-01-24 17:01:49,632 epoch 56 - iter 21/72 - loss 0.33538458\n",
      "2019-01-24 17:01:54,129 epoch 56 - iter 28/72 - loss 0.32634842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-24 17:01:58,579 epoch 56 - iter 35/72 - loss 0.34176773\n",
      "2019-01-24 17:02:02,857 epoch 56 - iter 42/72 - loss 0.40076766\n",
      "2019-01-24 17:02:06,996 epoch 56 - iter 49/72 - loss 0.39194273\n",
      "2019-01-24 17:02:11,489 epoch 56 - iter 56/72 - loss 0.38613439\n",
      "2019-01-24 17:02:16,303 epoch 56 - iter 63/72 - loss 0.37750649\n",
      "2019-01-24 17:02:21,137 epoch 56 - iter 70/72 - loss 0.38111891\n",
      "2019-01-24 17:02:21,420 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:02:21,422 EPOCH 56 done: loss 0.3797 - lr 0.0125 - bad epochs 0\n",
      "2019-01-24 17:02:22,837 DEV  : loss 0.24970274 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:02:30,919 TEST : loss 0.41684934 - f-score 0.9164 - acc 0.9164\n",
      "2019-01-24 17:02:30,921 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:02:31,555 epoch 57 - iter 0/72 - loss 0.28360754\n",
      "2019-01-24 17:02:36,126 epoch 57 - iter 7/72 - loss 0.20965962\n",
      "2019-01-24 17:02:40,649 epoch 57 - iter 14/72 - loss 0.52144182\n",
      "2019-01-24 17:02:45,442 epoch 57 - iter 21/72 - loss 0.48533486\n",
      "2019-01-24 17:02:50,306 epoch 57 - iter 28/72 - loss 0.43989048\n",
      "2019-01-24 17:02:55,270 epoch 57 - iter 35/72 - loss 0.39141721\n",
      "2019-01-24 17:02:59,589 epoch 57 - iter 42/72 - loss 0.38499167\n",
      "2019-01-24 17:03:04,482 epoch 57 - iter 49/72 - loss 0.37512956\n",
      "2019-01-24 17:03:08,706 epoch 57 - iter 56/72 - loss 0.36107388\n",
      "2019-01-24 17:03:13,105 epoch 57 - iter 63/72 - loss 0.37947778\n",
      "2019-01-24 17:03:17,769 epoch 57 - iter 70/72 - loss 0.37147939\n",
      "2019-01-24 17:03:18,140 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:03:18,142 EPOCH 57 done: loss 0.3814 - lr 0.0125 - bad epochs 1\n",
      "2019-01-24 17:03:20,346 DEV  : loss 0.23992571 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:03:28,107 TEST : loss 0.41804650 - f-score 0.9090 - acc 0.9089\n",
      "2019-01-24 17:03:28,109 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:03:28,808 epoch 58 - iter 0/72 - loss 1.40929365\n",
      "2019-01-24 17:03:33,870 epoch 58 - iter 7/72 - loss 0.48057192\n",
      "2019-01-24 17:03:38,089 epoch 58 - iter 14/72 - loss 0.40974915\n",
      "2019-01-24 17:03:42,466 epoch 58 - iter 21/72 - loss 0.42508612\n",
      "2019-01-24 17:03:46,810 epoch 58 - iter 28/72 - loss 0.39995634\n",
      "2019-01-24 17:03:51,494 epoch 58 - iter 35/72 - loss 0.41939063\n",
      "2019-01-24 17:03:55,771 epoch 58 - iter 42/72 - loss 0.41145650\n",
      "2019-01-24 17:04:00,043 epoch 58 - iter 49/72 - loss 0.38329899\n",
      "2019-01-24 17:04:04,730 epoch 58 - iter 56/72 - loss 0.38118636\n",
      "2019-01-24 17:04:09,372 epoch 58 - iter 63/72 - loss 0.38403064\n",
      "2019-01-24 17:04:14,205 epoch 58 - iter 70/72 - loss 0.37500395\n",
      "2019-01-24 17:04:14,435 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:04:14,437 EPOCH 58 done: loss 0.3739 - lr 0.0125 - bad epochs 2\n",
      "2019-01-24 17:04:15,967 DEV  : loss 0.25119656 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:04:23,802 TEST : loss 0.41970202 - f-score 0.9176 - acc 0.9176\n",
      "2019-01-24 17:04:23,806 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:04:24,380 epoch 59 - iter 0/72 - loss 0.41374755\n",
      "2019-01-24 17:04:28,625 epoch 59 - iter 7/72 - loss 0.31829206\n",
      "2019-01-24 17:04:33,083 epoch 59 - iter 14/72 - loss 0.31568881\n",
      "2019-01-24 17:04:37,603 epoch 59 - iter 21/72 - loss 0.26143520\n",
      "2019-01-24 17:04:42,123 epoch 59 - iter 28/72 - loss 0.28467410\n",
      "2019-01-24 17:04:46,978 epoch 59 - iter 35/72 - loss 0.28522171\n",
      "2019-01-24 17:04:51,528 epoch 59 - iter 42/72 - loss 0.31675830\n",
      "2019-01-24 17:04:55,939 epoch 59 - iter 49/72 - loss 0.32041402\n",
      "2019-01-24 17:05:00,359 epoch 59 - iter 56/72 - loss 0.34089558\n",
      "2019-01-24 17:05:04,689 epoch 59 - iter 63/72 - loss 0.34884396\n",
      "2019-01-24 17:05:09,095 epoch 59 - iter 70/72 - loss 0.34735430\n",
      "2019-01-24 17:05:09,351 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:05:09,354 EPOCH 59 done: loss 0.3463 - lr 0.0125 - bad epochs 3\n",
      "2019-01-24 17:05:11,081 DEV  : loss 0.24821696 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:05:19,274 TEST : loss 0.42426828 - f-score 0.9186 - acc 0.9187\n",
      "2019-01-24 17:05:21,837 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:05:22,488 epoch 60 - iter 0/72 - loss 0.32019925\n",
      "2019-01-24 17:05:27,002 epoch 60 - iter 7/72 - loss 0.22160935\n",
      "2019-01-24 17:05:32,097 epoch 60 - iter 14/72 - loss 0.37348314\n",
      "2019-01-24 17:05:36,544 epoch 60 - iter 21/72 - loss 0.34471268\n",
      "2019-01-24 17:05:40,994 epoch 60 - iter 28/72 - loss 0.35955269\n",
      "2019-01-24 17:05:45,498 epoch 60 - iter 35/72 - loss 0.34401238\n",
      "2019-01-24 17:05:50,307 epoch 60 - iter 42/72 - loss 0.36372408\n",
      "2019-01-24 17:05:54,877 epoch 60 - iter 49/72 - loss 0.37464882\n",
      "2019-01-24 17:05:59,613 epoch 60 - iter 56/72 - loss 0.37876696\n",
      "2019-01-24 17:06:04,021 epoch 60 - iter 63/72 - loss 0.38823826\n",
      "2019-01-24 17:06:08,457 epoch 60 - iter 70/72 - loss 0.38144153\n",
      "2019-01-24 17:06:08,714 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:06:08,716 EPOCH 60 done: loss 0.3853 - lr 0.0125 - bad epochs 0\n",
      "2019-01-24 17:06:10,160 DEV  : loss 0.25388178 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:06:18,533 TEST : loss 0.41970631 - f-score 0.9152 - acc 0.9152\n",
      "2019-01-24 17:06:18,536 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:06:19,175 epoch 61 - iter 0/72 - loss 0.44373226\n",
      "2019-01-24 17:06:23,453 epoch 61 - iter 7/72 - loss 0.27663200\n",
      "2019-01-24 17:06:28,069 epoch 61 - iter 14/72 - loss 0.32008786\n",
      "2019-01-24 17:06:32,982 epoch 61 - iter 21/72 - loss 0.40870225\n",
      "2019-01-24 17:06:37,841 epoch 61 - iter 28/72 - loss 0.41250334\n",
      "2019-01-24 17:06:42,430 epoch 61 - iter 35/72 - loss 0.42956139\n",
      "2019-01-24 17:06:46,974 epoch 61 - iter 42/72 - loss 0.42192044\n",
      "2019-01-24 17:06:51,573 epoch 61 - iter 49/72 - loss 0.42085336\n",
      "2019-01-24 17:06:56,192 epoch 61 - iter 56/72 - loss 0.41955639\n",
      "2019-01-24 17:07:00,564 epoch 61 - iter 63/72 - loss 0.40619252\n",
      "2019-01-24 17:07:05,227 epoch 61 - iter 70/72 - loss 0.38553139\n",
      "2019-01-24 17:07:05,468 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:07:05,470 EPOCH 61 done: loss 0.3844 - lr 0.0125 - bad epochs 1\n",
      "2019-01-24 17:07:07,028 DEV  : loss 0.25046742 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:07:15,215 TEST : loss 0.42258531 - f-score 0.9145 - acc 0.9145\n",
      "2019-01-24 17:07:15,218 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:07:15,860 epoch 62 - iter 0/72 - loss 0.40870512\n",
      "2019-01-24 17:07:20,624 epoch 62 - iter 7/72 - loss 0.31946394\n",
      "2019-01-24 17:07:25,107 epoch 62 - iter 14/72 - loss 0.37812321\n",
      "2019-01-24 17:07:29,854 epoch 62 - iter 21/72 - loss 0.35975329\n",
      "2019-01-24 17:07:34,253 epoch 62 - iter 28/72 - loss 0.32639483\n",
      "2019-01-24 17:07:38,865 epoch 62 - iter 35/72 - loss 0.30650147\n",
      "2019-01-24 17:07:43,562 epoch 62 - iter 42/72 - loss 0.32701700\n",
      "2019-01-24 17:07:47,931 epoch 62 - iter 49/72 - loss 0.31335424\n",
      "2019-01-24 17:07:52,554 epoch 62 - iter 56/72 - loss 0.35640521\n",
      "2019-01-24 17:07:56,988 epoch 62 - iter 63/72 - loss 0.35151856\n",
      "2019-01-24 17:08:01,619 epoch 62 - iter 70/72 - loss 0.34274436\n",
      "2019-01-24 17:08:01,870 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:08:01,872 EPOCH 62 done: loss 0.3414 - lr 0.0125 - bad epochs 2\n",
      "2019-01-24 17:08:03,309 DEV  : loss 0.24071063 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:08:12,436 TEST : loss 0.42222118 - f-score 0.9165 - acc 0.9165\n",
      "2019-01-24 17:08:15,178 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:08:15,916 epoch 63 - iter 0/72 - loss 0.03044951\n",
      "2019-01-24 17:08:20,701 epoch 63 - iter 7/72 - loss 0.46832290\n",
      "2019-01-24 17:08:25,371 epoch 63 - iter 14/72 - loss 0.52205908\n",
      "2019-01-24 17:08:29,968 epoch 63 - iter 21/72 - loss 0.45566074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-24 17:08:34,529 epoch 63 - iter 28/72 - loss 0.45961737\n",
      "2019-01-24 17:08:39,299 epoch 63 - iter 35/72 - loss 0.42215436\n",
      "2019-01-24 17:08:43,693 epoch 63 - iter 42/72 - loss 0.42849767\n",
      "2019-01-24 17:08:47,753 epoch 63 - iter 49/72 - loss 0.39350621\n",
      "2019-01-24 17:08:52,523 epoch 63 - iter 56/72 - loss 0.37871074\n",
      "2019-01-24 17:08:57,273 epoch 63 - iter 63/72 - loss 0.37149482\n",
      "2019-01-24 17:09:01,440 epoch 63 - iter 70/72 - loss 0.37124159\n",
      "2019-01-24 17:09:01,722 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:09:01,723 EPOCH 63 done: loss 0.3723 - lr 0.0125 - bad epochs 0\n",
      "2019-01-24 17:09:03,378 DEV  : loss 0.25640061 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:09:11,162 TEST : loss 0.42429525 - f-score 0.9126 - acc 0.9125\n",
      "2019-01-24 17:09:11,165 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:09:11,847 epoch 64 - iter 0/72 - loss 0.36217386\n",
      "2019-01-24 17:09:16,332 epoch 64 - iter 7/72 - loss 0.37210147\n",
      "2019-01-24 17:09:20,878 epoch 64 - iter 14/72 - loss 0.34978749\n",
      "2019-01-24 17:09:25,541 epoch 64 - iter 21/72 - loss 0.29874427\n",
      "2019-01-24 17:09:30,409 epoch 64 - iter 28/72 - loss 0.32688225\n",
      "2019-01-24 17:09:34,968 epoch 64 - iter 35/72 - loss 0.31163103\n",
      "2019-01-24 17:09:39,739 epoch 64 - iter 42/72 - loss 0.35513874\n",
      "2019-01-24 17:09:44,915 epoch 64 - iter 49/72 - loss 0.35960669\n",
      "2019-01-24 17:09:49,423 epoch 64 - iter 56/72 - loss 0.37397031\n",
      "2019-01-24 17:09:54,206 epoch 64 - iter 63/72 - loss 0.38998685\n",
      "2019-01-24 17:09:58,913 epoch 64 - iter 70/72 - loss 0.38805327\n",
      "2019-01-24 17:09:59,162 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:09:59,165 EPOCH 64 done: loss 0.3869 - lr 0.0125 - bad epochs 1\n",
      "2019-01-24 17:10:00,622 DEV  : loss 0.25156376 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:10:09,560 TEST : loss 0.42406228 - f-score 0.9169 - acc 0.9169\n",
      "2019-01-24 17:10:09,563 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:10:10,188 epoch 65 - iter 0/72 - loss 0.10897601\n",
      "2019-01-24 17:10:15,059 epoch 65 - iter 7/72 - loss 0.29590664\n",
      "2019-01-24 17:10:19,927 epoch 65 - iter 14/72 - loss 0.36926484\n",
      "2019-01-24 17:10:24,077 epoch 65 - iter 21/72 - loss 0.33300004\n",
      "2019-01-24 17:10:28,629 epoch 65 - iter 28/72 - loss 0.30544509\n",
      "2019-01-24 17:10:33,091 epoch 65 - iter 35/72 - loss 0.32207988\n",
      "2019-01-24 17:10:38,031 epoch 65 - iter 42/72 - loss 0.31949431\n",
      "2019-01-24 17:10:42,897 epoch 65 - iter 49/72 - loss 0.31007040\n",
      "2019-01-24 17:10:47,589 epoch 65 - iter 56/72 - loss 0.35478595\n",
      "2019-01-24 17:10:51,780 epoch 65 - iter 63/72 - loss 0.37398053\n",
      "2019-01-24 17:10:56,222 epoch 65 - iter 70/72 - loss 0.38057552\n",
      "2019-01-24 17:10:56,420 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:10:56,421 EPOCH 65 done: loss 0.3807 - lr 0.0125 - bad epochs 2\n",
      "2019-01-24 17:10:57,872 DEV  : loss 0.22864965 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:11:06,259 TEST : loss 0.41399950 - f-score 0.9189 - acc 0.9189\n",
      "2019-01-24 17:11:06,262 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:11:06,869 epoch 66 - iter 0/72 - loss 0.38784522\n",
      "2019-01-24 17:11:11,342 epoch 66 - iter 7/72 - loss 0.32331172\n",
      "2019-01-24 17:11:16,157 epoch 66 - iter 14/72 - loss 0.35187389\n",
      "2019-01-24 17:11:20,380 epoch 66 - iter 21/72 - loss 0.32276659\n",
      "2019-01-24 17:11:24,785 epoch 66 - iter 28/72 - loss 0.38179890\n",
      "2019-01-24 17:11:29,070 epoch 66 - iter 35/72 - loss 0.38589762\n",
      "2019-01-24 17:11:33,460 epoch 66 - iter 42/72 - loss 0.37433758\n",
      "2019-01-24 17:11:38,464 epoch 66 - iter 49/72 - loss 0.43953574\n",
      "2019-01-24 17:11:42,991 epoch 66 - iter 56/72 - loss 0.41813806\n",
      "2019-01-24 17:11:47,941 epoch 66 - iter 63/72 - loss 0.41077417\n",
      "2019-01-24 17:11:52,296 epoch 66 - iter 70/72 - loss 0.40254185\n",
      "2019-01-24 17:11:52,671 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:11:52,672 EPOCH 66 done: loss 0.4011 - lr 0.0125 - bad epochs 3\n",
      "2019-01-24 17:11:54,227 DEV  : loss 0.25279132 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:12:02,663 TEST : loss 0.43298447 - f-score 0.9195 - acc 0.9195\n",
      "Epoch    65: reducing learning rate of group 0 to 6.2500e-03.\n",
      "2019-01-24 17:12:02,666 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:12:03,341 epoch 67 - iter 0/72 - loss 0.03366396\n",
      "2019-01-24 17:12:07,837 epoch 67 - iter 7/72 - loss 0.20755725\n",
      "2019-01-24 17:12:12,647 epoch 67 - iter 14/72 - loss 0.20485559\n",
      "2019-01-24 17:12:17,067 epoch 67 - iter 21/72 - loss 0.26820174\n",
      "2019-01-24 17:12:22,071 epoch 67 - iter 28/72 - loss 0.28849282\n",
      "2019-01-24 17:12:26,511 epoch 67 - iter 35/72 - loss 0.35059867\n",
      "2019-01-24 17:12:30,547 epoch 67 - iter 42/72 - loss 0.34449180\n",
      "2019-01-24 17:12:35,490 epoch 67 - iter 49/72 - loss 0.38876700\n",
      "2019-01-24 17:12:39,848 epoch 67 - iter 56/72 - loss 0.38068036\n",
      "2019-01-24 17:12:44,102 epoch 67 - iter 63/72 - loss 0.37584059\n",
      "2019-01-24 17:12:48,691 epoch 67 - iter 70/72 - loss 0.36270439\n",
      "2019-01-24 17:12:48,973 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:12:48,975 EPOCH 67 done: loss 0.3614 - lr 0.0063 - bad epochs 0\n",
      "2019-01-24 17:12:50,559 DEV  : loss 0.24623875 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:12:58,443 TEST : loss 0.42496216 - f-score 0.9161 - acc 0.9161\n",
      "2019-01-24 17:12:58,445 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:12:59,152 epoch 68 - iter 0/72 - loss 0.23879504\n",
      "2019-01-24 17:13:03,758 epoch 68 - iter 7/72 - loss 0.41086931\n",
      "2019-01-24 17:13:08,696 epoch 68 - iter 14/72 - loss 0.39437371\n",
      "2019-01-24 17:13:13,193 epoch 68 - iter 21/72 - loss 0.40024894\n",
      "2019-01-24 17:13:17,794 epoch 68 - iter 28/72 - loss 0.35919456\n",
      "2019-01-24 17:13:22,319 epoch 68 - iter 35/72 - loss 0.35852938\n",
      "2019-01-24 17:13:26,561 epoch 68 - iter 42/72 - loss 0.33004240\n",
      "2019-01-24 17:13:31,386 epoch 68 - iter 49/72 - loss 0.34513578\n",
      "2019-01-24 17:13:36,174 epoch 68 - iter 56/72 - loss 0.34401436\n",
      "2019-01-24 17:13:40,335 epoch 68 - iter 63/72 - loss 0.36282975\n",
      "2019-01-24 17:13:44,690 epoch 68 - iter 70/72 - loss 0.34447437\n",
      "2019-01-24 17:13:45,004 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:13:45,006 EPOCH 68 done: loss 0.3435 - lr 0.0063 - bad epochs 1\n",
      "2019-01-24 17:13:47,687 DEV  : loss 0.24097605 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:13:55,822 TEST : loss 0.42047566 - f-score 0.9170 - acc 0.9170\n",
      "2019-01-24 17:13:55,826 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:13:56,576 epoch 69 - iter 0/72 - loss 0.05211246\n",
      "2019-01-24 17:14:01,243 epoch 69 - iter 7/72 - loss 0.24010082\n",
      "2019-01-24 17:14:05,819 epoch 69 - iter 14/72 - loss 0.32158638\n",
      "2019-01-24 17:14:10,627 epoch 69 - iter 21/72 - loss 0.30558823\n",
      "2019-01-24 17:14:15,279 epoch 69 - iter 28/72 - loss 0.27752121\n",
      "2019-01-24 17:14:19,904 epoch 69 - iter 35/72 - loss 0.31576818\n",
      "2019-01-24 17:14:24,337 epoch 69 - iter 42/72 - loss 0.32479683\n",
      "2019-01-24 17:14:28,670 epoch 69 - iter 49/72 - loss 0.32942009\n",
      "2019-01-24 17:14:33,349 epoch 69 - iter 56/72 - loss 0.32355491\n",
      "2019-01-24 17:14:38,183 epoch 69 - iter 63/72 - loss 0.31714731\n",
      "2019-01-24 17:14:42,469 epoch 69 - iter 70/72 - loss 0.33622648\n",
      "2019-01-24 17:14:42,846 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:14:42,848 EPOCH 69 done: loss 0.3425 - lr 0.0063 - bad epochs 2\n",
      "2019-01-24 17:14:44,362 DEV  : loss 0.24438402 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:14:52,178 TEST : loss 0.42295262 - f-score 0.9218 - acc 0.9218\n",
      "2019-01-24 17:14:52,181 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:14:52,798 epoch 70 - iter 0/72 - loss 0.07047343\n",
      "2019-01-24 17:14:57,532 epoch 70 - iter 7/72 - loss 0.39931707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-24 17:15:02,066 epoch 70 - iter 14/72 - loss 0.39679316\n",
      "2019-01-24 17:15:06,243 epoch 70 - iter 21/72 - loss 0.36879033\n",
      "2019-01-24 17:15:10,520 epoch 70 - iter 28/72 - loss 0.33060300\n",
      "2019-01-24 17:15:15,063 epoch 70 - iter 35/72 - loss 0.31469344\n",
      "2019-01-24 17:15:19,763 epoch 70 - iter 42/72 - loss 0.31612374\n",
      "2019-01-24 17:15:24,570 epoch 70 - iter 49/72 - loss 0.33258257\n",
      "2019-01-24 17:15:29,037 epoch 70 - iter 56/72 - loss 0.32954421\n",
      "2019-01-24 17:15:33,347 epoch 70 - iter 63/72 - loss 0.33408408\n",
      "2019-01-24 17:15:37,878 epoch 70 - iter 70/72 - loss 0.34755536\n",
      "2019-01-24 17:15:38,182 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:15:38,184 EPOCH 70 done: loss 0.3466 - lr 0.0063 - bad epochs 3\n",
      "2019-01-24 17:15:39,684 DEV  : loss 0.24249567 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:15:48,059 TEST : loss 0.42113608 - f-score 0.9217 - acc 0.9217\n",
      "Epoch    69: reducing learning rate of group 0 to 3.1250e-03.\n",
      "2019-01-24 17:15:48,062 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:15:48,685 epoch 71 - iter 0/72 - loss 1.49319458\n",
      "2019-01-24 17:15:53,253 epoch 71 - iter 7/72 - loss 0.43484651\n",
      "2019-01-24 17:15:57,899 epoch 71 - iter 14/72 - loss 0.36884205\n",
      "2019-01-24 17:16:02,817 epoch 71 - iter 21/72 - loss 0.36210760\n",
      "2019-01-24 17:16:07,319 epoch 71 - iter 28/72 - loss 0.33011282\n",
      "2019-01-24 17:16:12,012 epoch 71 - iter 35/72 - loss 0.34478674\n",
      "2019-01-24 17:16:16,234 epoch 71 - iter 42/72 - loss 0.32628752\n",
      "2019-01-24 17:16:20,423 epoch 71 - iter 49/72 - loss 0.32648258\n",
      "2019-01-24 17:16:25,257 epoch 71 - iter 56/72 - loss 0.34981956\n",
      "2019-01-24 17:16:29,725 epoch 71 - iter 63/72 - loss 0.34042481\n",
      "2019-01-24 17:16:34,244 epoch 71 - iter 70/72 - loss 0.34969659\n",
      "2019-01-24 17:16:34,548 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:16:34,550 EPOCH 71 done: loss 0.3494 - lr 0.0031 - bad epochs 0\n",
      "2019-01-24 17:16:36,231 DEV  : loss 0.23807758 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:16:43,795 TEST : loss 0.41792819 - f-score 0.9185 - acc 0.9185\n",
      "2019-01-24 17:16:43,799 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:16:44,508 epoch 72 - iter 0/72 - loss 0.03697908\n",
      "2019-01-24 17:16:49,007 epoch 72 - iter 7/72 - loss 0.34593603\n",
      "2019-01-24 17:16:53,722 epoch 72 - iter 14/72 - loss 0.39726574\n",
      "2019-01-24 17:16:58,105 epoch 72 - iter 21/72 - loss 0.40071823\n",
      "2019-01-24 17:17:02,638 epoch 72 - iter 28/72 - loss 0.38646228\n",
      "2019-01-24 17:17:07,121 epoch 72 - iter 35/72 - loss 0.37011437\n",
      "2019-01-24 17:17:11,849 epoch 72 - iter 42/72 - loss 0.37043689\n",
      "2019-01-24 17:17:15,956 epoch 72 - iter 49/72 - loss 0.36475115\n",
      "2019-01-24 17:17:20,263 epoch 72 - iter 56/72 - loss 0.36592358\n",
      "2019-01-24 17:17:24,864 epoch 72 - iter 63/72 - loss 0.35910543\n",
      "2019-01-24 17:17:29,556 epoch 72 - iter 70/72 - loss 0.35193520\n",
      "2019-01-24 17:17:29,881 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:17:29,883 EPOCH 72 done: loss 0.3507 - lr 0.0031 - bad epochs 1\n",
      "2019-01-24 17:17:31,260 DEV  : loss 0.24097469 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:17:39,035 TEST : loss 0.42078069 - f-score 0.9218 - acc 0.9218\n",
      "2019-01-24 17:17:39,038 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:17:39,860 epoch 73 - iter 0/72 - loss 0.27008936\n",
      "2019-01-24 17:17:44,657 epoch 73 - iter 7/72 - loss 0.47390311\n",
      "2019-01-24 17:17:49,464 epoch 73 - iter 14/72 - loss 0.42503713\n",
      "2019-01-24 17:17:53,938 epoch 73 - iter 21/72 - loss 0.38818160\n",
      "2019-01-24 17:17:58,612 epoch 73 - iter 28/72 - loss 0.38274265\n",
      "2019-01-24 17:18:03,328 epoch 73 - iter 35/72 - loss 0.40574766\n",
      "2019-01-24 17:18:08,090 epoch 73 - iter 42/72 - loss 0.37505252\n",
      "2019-01-24 17:18:12,440 epoch 73 - iter 49/72 - loss 0.36459216\n",
      "2019-01-24 17:18:17,143 epoch 73 - iter 56/72 - loss 0.35278248\n",
      "2019-01-24 17:18:21,518 epoch 73 - iter 63/72 - loss 0.35929147\n",
      "2019-01-24 17:18:26,155 epoch 73 - iter 70/72 - loss 0.37048501\n",
      "2019-01-24 17:18:26,439 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:18:26,440 EPOCH 73 done: loss 0.3691 - lr 0.0031 - bad epochs 2\n",
      "2019-01-24 17:18:27,985 DEV  : loss 0.24022098 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:18:36,771 TEST : loss 0.42153159 - f-score 0.9203 - acc 0.9203\n",
      "2019-01-24 17:18:36,774 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:18:37,424 epoch 74 - iter 0/72 - loss 0.01767254\n",
      "2019-01-24 17:18:42,072 epoch 74 - iter 7/72 - loss 0.31884830\n",
      "2019-01-24 17:18:46,463 epoch 74 - iter 14/72 - loss 0.37331051\n",
      "2019-01-24 17:18:50,910 epoch 74 - iter 21/72 - loss 0.43653672\n",
      "2019-01-24 17:18:55,320 epoch 74 - iter 28/72 - loss 0.42028736\n",
      "2019-01-24 17:18:59,791 epoch 74 - iter 35/72 - loss 0.40558898\n",
      "2019-01-24 17:19:04,106 epoch 74 - iter 42/72 - loss 0.37711136\n",
      "2019-01-24 17:19:09,010 epoch 74 - iter 49/72 - loss 0.35318437\n",
      "2019-01-24 17:19:13,524 epoch 74 - iter 56/72 - loss 0.35975569\n",
      "2019-01-24 17:19:18,194 epoch 74 - iter 63/72 - loss 0.36567160\n",
      "2019-01-24 17:19:22,925 epoch 74 - iter 70/72 - loss 0.35711631\n",
      "2019-01-24 17:19:23,189 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:19:23,190 EPOCH 74 done: loss 0.3611 - lr 0.0031 - bad epochs 3\n",
      "2019-01-24 17:19:24,662 DEV  : loss 0.23717289 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:19:33,139 TEST : loss 0.41990435 - f-score 0.9218 - acc 0.9218\n",
      "Epoch    73: reducing learning rate of group 0 to 1.5625e-03.\n",
      "2019-01-24 17:19:33,142 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:19:33,879 epoch 75 - iter 0/72 - loss 0.14886045\n",
      "2019-01-24 17:19:38,742 epoch 75 - iter 7/72 - loss 0.42649019\n",
      "2019-01-24 17:19:43,523 epoch 75 - iter 14/72 - loss 0.40190477\n",
      "2019-01-24 17:19:48,491 epoch 75 - iter 21/72 - loss 0.36430555\n",
      "2019-01-24 17:19:53,089 epoch 75 - iter 28/72 - loss 0.32371598\n",
      "2019-01-24 17:19:57,988 epoch 75 - iter 35/72 - loss 0.31213272\n",
      "2019-01-24 17:20:02,750 epoch 75 - iter 42/72 - loss 0.34864308\n",
      "2019-01-24 17:20:07,189 epoch 75 - iter 49/72 - loss 0.35650935\n",
      "2019-01-24 17:20:11,682 epoch 75 - iter 56/72 - loss 0.35601090\n",
      "2019-01-24 17:20:16,491 epoch 75 - iter 63/72 - loss 0.34013483\n",
      "2019-01-24 17:20:20,543 epoch 75 - iter 70/72 - loss 0.32559583\n",
      "2019-01-24 17:20:20,752 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:20:20,754 EPOCH 75 done: loss 0.3257 - lr 0.0016 - bad epochs 0\n",
      "2019-01-24 17:20:22,178 DEV  : loss 0.23867451 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:20:30,212 TEST : loss 0.41983604 - f-score 0.9185 - acc 0.9185\n",
      "2019-01-24 17:20:32,823 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:20:33,442 epoch 76 - iter 0/72 - loss 0.06313205\n",
      "2019-01-24 17:20:38,128 epoch 76 - iter 7/72 - loss 0.22802777\n",
      "2019-01-24 17:20:42,475 epoch 76 - iter 14/72 - loss 0.39365426\n",
      "2019-01-24 17:20:47,355 epoch 76 - iter 21/72 - loss 0.34653706\n",
      "2019-01-24 17:20:52,095 epoch 76 - iter 28/72 - loss 0.32444916\n",
      "2019-01-24 17:20:56,718 epoch 76 - iter 35/72 - loss 0.31738176\n",
      "2019-01-24 17:21:01,331 epoch 76 - iter 42/72 - loss 0.33476012\n",
      "2019-01-24 17:21:05,941 epoch 76 - iter 49/72 - loss 0.33346539\n",
      "2019-01-24 17:21:10,567 epoch 76 - iter 56/72 - loss 0.31181911\n",
      "2019-01-24 17:21:14,941 epoch 76 - iter 63/72 - loss 0.30947058\n",
      "2019-01-24 17:21:19,805 epoch 76 - iter 70/72 - loss 0.32402325\n",
      "2019-01-24 17:21:20,172 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:21:20,174 EPOCH 76 done: loss 0.3270 - lr 0.0016 - bad epochs 0\n",
      "2019-01-24 17:21:21,668 DEV  : loss 0.23802239 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:21:29,362 TEST : loss 0.41910163 - f-score 0.9218 - acc 0.9218\n",
      "2019-01-24 17:21:29,365 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-24 17:21:29,955 epoch 77 - iter 0/72 - loss 0.10195108\n",
      "2019-01-24 17:21:35,041 epoch 77 - iter 7/72 - loss 0.31974821\n",
      "2019-01-24 17:21:39,493 epoch 77 - iter 14/72 - loss 0.40219005\n",
      "2019-01-24 17:21:44,077 epoch 77 - iter 21/72 - loss 0.40036717\n",
      "2019-01-24 17:21:48,938 epoch 77 - iter 28/72 - loss 0.40614637\n",
      "2019-01-24 17:21:53,647 epoch 77 - iter 35/72 - loss 0.40443556\n",
      "2019-01-24 17:21:58,201 epoch 77 - iter 42/72 - loss 0.36774668\n",
      "2019-01-24 17:22:02,627 epoch 77 - iter 49/72 - loss 0.34175107\n",
      "2019-01-24 17:22:07,490 epoch 77 - iter 56/72 - loss 0.36669382\n",
      "2019-01-24 17:22:12,768 epoch 77 - iter 63/72 - loss 0.36035304\n",
      "2019-01-24 17:22:16,959 epoch 77 - iter 70/72 - loss 0.34962307\n",
      "2019-01-24 17:22:17,203 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:22:17,204 EPOCH 77 done: loss 0.3485 - lr 0.0016 - bad epochs 1\n",
      "2019-01-24 17:22:18,630 DEV  : loss 0.23805480 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:22:26,218 TEST : loss 0.41782853 - f-score 0.9218 - acc 0.9218\n",
      "2019-01-24 17:22:26,221 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:22:26,902 epoch 78 - iter 0/72 - loss 0.07919405\n",
      "2019-01-24 17:22:31,648 epoch 78 - iter 7/72 - loss 0.19552357\n",
      "2019-01-24 17:22:35,831 epoch 78 - iter 14/72 - loss 0.30693517\n",
      "2019-01-24 17:22:40,426 epoch 78 - iter 21/72 - loss 0.34091679\n",
      "2019-01-24 17:22:45,073 epoch 78 - iter 28/72 - loss 0.35852384\n",
      "2019-01-24 17:22:49,234 epoch 78 - iter 35/72 - loss 0.36217859\n",
      "2019-01-24 17:22:54,016 epoch 78 - iter 42/72 - loss 0.33984288\n",
      "2019-01-24 17:22:58,405 epoch 78 - iter 49/72 - loss 0.34388258\n",
      "2019-01-24 17:23:02,720 epoch 78 - iter 56/72 - loss 0.36204151\n",
      "2019-01-24 17:23:07,595 epoch 78 - iter 63/72 - loss 0.35853894\n",
      "2019-01-24 17:23:12,184 epoch 78 - iter 70/72 - loss 0.36594343\n",
      "2019-01-24 17:23:12,415 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:23:12,417 EPOCH 78 done: loss 0.3646 - lr 0.0016 - bad epochs 2\n",
      "2019-01-24 17:23:13,839 DEV  : loss 0.23571581 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:23:21,466 TEST : loss 0.41729781 - f-score 0.9218 - acc 0.9218\n",
      "2019-01-24 17:23:21,470 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:23:22,185 epoch 79 - iter 0/72 - loss 0.74422693\n",
      "2019-01-24 17:23:26,686 epoch 79 - iter 7/72 - loss 0.29273899\n",
      "2019-01-24 17:23:30,965 epoch 79 - iter 14/72 - loss 0.22916132\n",
      "2019-01-24 17:23:35,710 epoch 79 - iter 21/72 - loss 0.27680974\n",
      "2019-01-24 17:23:40,804 epoch 79 - iter 28/72 - loss 0.37150967\n",
      "2019-01-24 17:23:45,571 epoch 79 - iter 35/72 - loss 0.37425204\n",
      "2019-01-24 17:23:50,015 epoch 79 - iter 42/72 - loss 0.35923823\n",
      "2019-01-24 17:23:54,659 epoch 79 - iter 49/72 - loss 0.36205039\n",
      "2019-01-24 17:23:59,391 epoch 79 - iter 56/72 - loss 0.34654221\n",
      "2019-01-24 17:24:04,292 epoch 79 - iter 63/72 - loss 0.33888610\n",
      "2019-01-24 17:24:09,052 epoch 79 - iter 70/72 - loss 0.33029698\n",
      "2019-01-24 17:24:09,324 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:24:09,325 EPOCH 79 done: loss 0.3291 - lr 0.0016 - bad epochs 3\n",
      "2019-01-24 17:24:11,589 DEV  : loss 0.23759042 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:24:19,420 TEST : loss 0.41873696 - f-score 0.9218 - acc 0.9218\n",
      "Epoch    78: reducing learning rate of group 0 to 7.8125e-04.\n",
      "2019-01-24 17:24:19,424 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:24:20,065 epoch 80 - iter 0/72 - loss 0.25524381\n",
      "2019-01-24 17:24:24,759 epoch 80 - iter 7/72 - loss 0.33354363\n",
      "2019-01-24 17:24:29,235 epoch 80 - iter 14/72 - loss 0.29005316\n",
      "2019-01-24 17:24:33,953 epoch 80 - iter 21/72 - loss 0.32921061\n",
      "2019-01-24 17:24:38,265 epoch 80 - iter 28/72 - loss 0.33942867\n",
      "2019-01-24 17:24:42,779 epoch 80 - iter 35/72 - loss 0.33553399\n",
      "2019-01-24 17:24:47,490 epoch 80 - iter 42/72 - loss 0.35872699\n",
      "2019-01-24 17:24:52,332 epoch 80 - iter 49/72 - loss 0.38064642\n",
      "2019-01-24 17:24:56,782 epoch 80 - iter 56/72 - loss 0.36595067\n",
      "2019-01-24 17:25:01,479 epoch 80 - iter 63/72 - loss 0.35273228\n",
      "2019-01-24 17:25:05,861 epoch 80 - iter 70/72 - loss 0.33859597\n",
      "2019-01-24 17:25:06,088 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:25:06,090 EPOCH 80 done: loss 0.3416 - lr 0.0008 - bad epochs 0\n",
      "2019-01-24 17:25:07,521 DEV  : loss 0.23756137 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:25:15,474 TEST : loss 0.41909233 - f-score 0.9218 - acc 0.9218\n",
      "2019-01-24 17:25:15,478 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:25:16,185 epoch 81 - iter 0/72 - loss 0.21639055\n",
      "2019-01-24 17:25:20,556 epoch 81 - iter 7/72 - loss 0.34724072\n",
      "2019-01-24 17:25:25,305 epoch 81 - iter 14/72 - loss 0.63482737\n",
      "2019-01-24 17:25:30,072 epoch 81 - iter 21/72 - loss 0.51838774\n",
      "2019-01-24 17:25:34,605 epoch 81 - iter 28/72 - loss 0.47675700\n",
      "2019-01-24 17:25:38,812 epoch 81 - iter 35/72 - loss 0.41402282\n",
      "2019-01-24 17:25:43,470 epoch 81 - iter 42/72 - loss 0.41066340\n",
      "2019-01-24 17:25:47,910 epoch 81 - iter 49/72 - loss 0.41445314\n",
      "2019-01-24 17:25:52,529 epoch 81 - iter 56/72 - loss 0.38511809\n",
      "2019-01-24 17:25:57,123 epoch 81 - iter 63/72 - loss 0.37180156\n",
      "2019-01-24 17:26:01,523 epoch 81 - iter 70/72 - loss 0.36158355\n",
      "2019-01-24 17:26:01,971 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:26:01,973 EPOCH 81 done: loss 0.3603 - lr 0.0008 - bad epochs 1\n",
      "2019-01-24 17:26:03,640 DEV  : loss 0.23526770 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:26:11,045 TEST : loss 0.41804081 - f-score 0.9210 - acc 0.9211\n",
      "2019-01-24 17:26:11,048 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:26:11,729 epoch 82 - iter 0/72 - loss 0.30752373\n",
      "2019-01-24 17:26:16,029 epoch 82 - iter 7/72 - loss 0.29833005\n",
      "2019-01-24 17:26:20,603 epoch 82 - iter 14/72 - loss 0.23804431\n",
      "2019-01-24 17:26:25,446 epoch 82 - iter 21/72 - loss 0.29683739\n",
      "2019-01-24 17:26:29,810 epoch 82 - iter 28/72 - loss 0.30187082\n",
      "2019-01-24 17:26:34,693 epoch 82 - iter 35/72 - loss 0.30732285\n",
      "2019-01-24 17:26:39,391 epoch 82 - iter 42/72 - loss 0.28847883\n",
      "2019-01-24 17:26:43,745 epoch 82 - iter 49/72 - loss 0.33665524\n",
      "2019-01-24 17:26:48,388 epoch 82 - iter 56/72 - loss 0.32487277\n",
      "2019-01-24 17:26:52,961 epoch 82 - iter 63/72 - loss 0.33212554\n",
      "2019-01-24 17:26:57,428 epoch 82 - iter 70/72 - loss 0.33652914\n",
      "2019-01-24 17:26:57,725 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:26:57,727 EPOCH 82 done: loss 0.3374 - lr 0.0008 - bad epochs 2\n",
      "2019-01-24 17:26:59,219 DEV  : loss 0.23602386 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:27:06,883 TEST : loss 0.41824824 - f-score 0.9210 - acc 0.9211\n",
      "2019-01-24 17:27:06,886 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:27:07,542 epoch 83 - iter 0/72 - loss 0.45511362\n",
      "2019-01-24 17:27:12,107 epoch 83 - iter 7/72 - loss 0.18839637\n",
      "2019-01-24 17:27:16,712 epoch 83 - iter 14/72 - loss 0.27120325\n",
      "2019-01-24 17:27:21,288 epoch 83 - iter 21/72 - loss 0.29664312\n",
      "2019-01-24 17:27:26,256 epoch 83 - iter 28/72 - loss 0.36544092\n",
      "2019-01-24 17:27:30,598 epoch 83 - iter 35/72 - loss 0.35748810\n",
      "2019-01-24 17:27:35,640 epoch 83 - iter 42/72 - loss 0.34665737\n",
      "2019-01-24 17:27:40,146 epoch 83 - iter 49/72 - loss 0.37456423\n",
      "2019-01-24 17:27:44,804 epoch 83 - iter 56/72 - loss 0.35984634\n",
      "2019-01-24 17:27:49,041 epoch 83 - iter 63/72 - loss 0.36976998\n",
      "2019-01-24 17:27:53,627 epoch 83 - iter 70/72 - loss 0.37577055\n",
      "2019-01-24 17:27:53,899 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:27:53,900 EPOCH 83 done: loss 0.3743 - lr 0.0008 - bad epochs 3\n",
      "2019-01-24 17:27:55,364 DEV  : loss 0.23560697 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:28:02,840 TEST : loss 0.41776952 - f-score 0.9210 - acc 0.9211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    82: reducing learning rate of group 0 to 3.9063e-04.\n",
      "2019-01-24 17:28:02,844 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:28:03,436 epoch 84 - iter 0/72 - loss 0.04405427\n",
      "2019-01-24 17:28:08,011 epoch 84 - iter 7/72 - loss 0.37800818\n",
      "2019-01-24 17:28:12,159 epoch 84 - iter 14/72 - loss 0.38161844\n",
      "2019-01-24 17:28:16,274 epoch 84 - iter 21/72 - loss 0.35018046\n",
      "2019-01-24 17:28:21,055 epoch 84 - iter 28/72 - loss 0.34377812\n",
      "2019-01-24 17:28:25,920 epoch 84 - iter 35/72 - loss 0.40821773\n",
      "2019-01-24 17:28:30,839 epoch 84 - iter 42/72 - loss 0.37360732\n",
      "2019-01-24 17:28:35,725 epoch 84 - iter 49/72 - loss 0.36550734\n",
      "2019-01-24 17:28:40,380 epoch 84 - iter 56/72 - loss 0.35124270\n",
      "2019-01-24 17:28:44,774 epoch 84 - iter 63/72 - loss 0.34351734\n",
      "2019-01-24 17:28:48,929 epoch 84 - iter 70/72 - loss 0.35050511\n",
      "2019-01-24 17:28:49,246 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:28:49,248 EPOCH 84 done: loss 0.3494 - lr 0.0004 - bad epochs 0\n",
      "2019-01-24 17:28:50,665 DEV  : loss 0.23622628 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:28:59,390 TEST : loss 0.41813061 - f-score 0.9210 - acc 0.9211\n",
      "2019-01-24 17:28:59,394 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:29:00,096 epoch 85 - iter 0/72 - loss 0.44735980\n",
      "2019-01-24 17:29:04,915 epoch 85 - iter 7/72 - loss 0.35346268\n",
      "2019-01-24 17:29:09,684 epoch 85 - iter 14/72 - loss 0.34919892\n",
      "2019-01-24 17:29:14,040 epoch 85 - iter 21/72 - loss 0.35711710\n",
      "2019-01-24 17:29:18,594 epoch 85 - iter 28/72 - loss 0.34917524\n",
      "2019-01-24 17:29:23,308 epoch 85 - iter 35/72 - loss 0.33666384\n",
      "2019-01-24 17:29:27,887 epoch 85 - iter 42/72 - loss 0.32099104\n",
      "2019-01-24 17:29:32,302 epoch 85 - iter 49/72 - loss 0.34376931\n",
      "2019-01-24 17:29:36,605 epoch 85 - iter 56/72 - loss 0.36299627\n",
      "2019-01-24 17:29:40,871 epoch 85 - iter 63/72 - loss 0.35350729\n",
      "2019-01-24 17:29:45,370 epoch 85 - iter 70/72 - loss 0.37073169\n",
      "2019-01-24 17:29:45,736 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:29:45,738 EPOCH 85 done: loss 0.3694 - lr 0.0004 - bad epochs 1\n",
      "2019-01-24 17:29:47,189 DEV  : loss 0.23555864 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:29:55,081 TEST : loss 0.41745305 - f-score 0.9210 - acc 0.9211\n",
      "2019-01-24 17:29:55,084 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:29:55,728 epoch 86 - iter 0/72 - loss 0.25209638\n",
      "2019-01-24 17:30:00,468 epoch 86 - iter 7/72 - loss 0.25725180\n",
      "2019-01-24 17:30:04,601 epoch 86 - iter 14/72 - loss 0.34175430\n",
      "2019-01-24 17:30:09,122 epoch 86 - iter 21/72 - loss 0.32186032\n",
      "2019-01-24 17:30:13,784 epoch 86 - iter 28/72 - loss 0.34593615\n",
      "2019-01-24 17:30:18,645 epoch 86 - iter 35/72 - loss 0.31770859\n",
      "2019-01-24 17:30:23,104 epoch 86 - iter 42/72 - loss 0.33026221\n",
      "2019-01-24 17:30:27,774 epoch 86 - iter 49/72 - loss 0.35179575\n",
      "2019-01-24 17:30:32,598 epoch 86 - iter 56/72 - loss 0.35659991\n",
      "2019-01-24 17:30:37,634 epoch 86 - iter 63/72 - loss 0.36202210\n",
      "2019-01-24 17:30:41,845 epoch 86 - iter 70/72 - loss 0.36113810\n",
      "2019-01-24 17:30:42,044 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:30:42,046 EPOCH 86 done: loss 0.3599 - lr 0.0004 - bad epochs 2\n",
      "2019-01-24 17:30:43,609 DEV  : loss 0.23502190 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:30:51,792 TEST : loss 0.41681945 - f-score 0.9210 - acc 0.9211\n",
      "2019-01-24 17:30:51,795 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:30:52,481 epoch 87 - iter 0/72 - loss 0.59061342\n",
      "2019-01-24 17:30:56,997 epoch 87 - iter 7/72 - loss 0.32969177\n",
      "2019-01-24 17:31:01,435 epoch 87 - iter 14/72 - loss 0.29366170\n",
      "2019-01-24 17:31:05,713 epoch 87 - iter 21/72 - loss 0.27815629\n",
      "2019-01-24 17:31:10,283 epoch 87 - iter 28/72 - loss 0.30719439\n",
      "2019-01-24 17:31:14,797 epoch 87 - iter 35/72 - loss 0.27980235\n",
      "2019-01-24 17:31:19,457 epoch 87 - iter 42/72 - loss 0.28168686\n",
      "2019-01-24 17:31:23,682 epoch 87 - iter 49/72 - loss 0.30106845\n",
      "2019-01-24 17:31:28,328 epoch 87 - iter 56/72 - loss 0.33606485\n",
      "2019-01-24 17:31:33,086 epoch 87 - iter 63/72 - loss 0.34133801\n",
      "2019-01-24 17:31:38,084 epoch 87 - iter 70/72 - loss 0.35274028\n",
      "2019-01-24 17:31:38,418 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:31:38,420 EPOCH 87 done: loss 0.3514 - lr 0.0004 - bad epochs 3\n",
      "2019-01-24 17:31:39,999 DEV  : loss 0.23601052 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:31:47,815 TEST : loss 0.41739890 - f-score 0.9210 - acc 0.9211\n",
      "Epoch    86: reducing learning rate of group 0 to 1.9531e-04.\n",
      "2019-01-24 17:31:47,818 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:31:48,498 epoch 88 - iter 0/72 - loss 0.90729469\n",
      "2019-01-24 17:31:53,006 epoch 88 - iter 7/72 - loss 0.53260742\n",
      "2019-01-24 17:31:57,826 epoch 88 - iter 14/72 - loss 0.46147299\n",
      "2019-01-24 17:32:02,268 epoch 88 - iter 21/72 - loss 0.39863821\n",
      "2019-01-24 17:32:07,160 epoch 88 - iter 28/72 - loss 0.39965023\n",
      "2019-01-24 17:32:11,649 epoch 88 - iter 35/72 - loss 0.35284912\n",
      "2019-01-24 17:32:16,370 epoch 88 - iter 42/72 - loss 0.36192243\n",
      "2019-01-24 17:32:20,471 epoch 88 - iter 49/72 - loss 0.35237785\n",
      "2019-01-24 17:32:24,820 epoch 88 - iter 56/72 - loss 0.33776837\n",
      "2019-01-24 17:32:29,243 epoch 88 - iter 63/72 - loss 0.32730118\n",
      "2019-01-24 17:32:34,499 epoch 88 - iter 70/72 - loss 0.32982250\n",
      "2019-01-24 17:32:34,932 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:32:34,936 EPOCH 88 done: loss 0.3289 - lr 0.0002 - bad epochs 0\n",
      "2019-01-24 17:32:36,458 DEV  : loss 0.23650405 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:32:44,609 TEST : loss 0.41760975 - f-score 0.9210 - acc 0.9211\n",
      "2019-01-24 17:32:44,614 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:32:45,343 epoch 89 - iter 0/72 - loss 0.68897307\n",
      "2019-01-24 17:32:49,978 epoch 89 - iter 7/72 - loss 0.43864726\n",
      "2019-01-24 17:32:54,403 epoch 89 - iter 14/72 - loss 0.44859388\n",
      "2019-01-24 17:32:59,175 epoch 89 - iter 21/72 - loss 0.35712387\n",
      "2019-01-24 17:33:03,726 epoch 89 - iter 28/72 - loss 0.31730429\n",
      "2019-01-24 17:33:08,245 epoch 89 - iter 35/72 - loss 0.32092101\n",
      "2019-01-24 17:33:12,824 epoch 89 - iter 42/72 - loss 0.33377116\n",
      "2019-01-24 17:33:17,632 epoch 89 - iter 49/72 - loss 0.35083454\n",
      "2019-01-24 17:33:22,489 epoch 89 - iter 56/72 - loss 0.34451380\n",
      "2019-01-24 17:33:27,001 epoch 89 - iter 63/72 - loss 0.34834671\n",
      "2019-01-24 17:33:31,466 epoch 89 - iter 70/72 - loss 0.34473282\n",
      "2019-01-24 17:33:31,786 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:33:31,788 EPOCH 89 done: loss 0.3447 - lr 0.0002 - bad epochs 1\n",
      "2019-01-24 17:33:33,363 DEV  : loss 0.23663148 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:33:41,650 TEST : loss 0.41753414 - f-score 0.9210 - acc 0.9211\n",
      "2019-01-24 17:33:41,654 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:33:42,413 epoch 90 - iter 0/72 - loss 0.06959188\n",
      "2019-01-24 17:33:46,969 epoch 90 - iter 7/72 - loss 0.26250456\n",
      "2019-01-24 17:33:51,907 epoch 90 - iter 14/72 - loss 0.27361975\n",
      "2019-01-24 17:33:56,282 epoch 90 - iter 21/72 - loss 0.27766307\n",
      "2019-01-24 17:34:01,167 epoch 90 - iter 28/72 - loss 0.33002926\n",
      "2019-01-24 17:34:05,915 epoch 90 - iter 35/72 - loss 0.34074060\n",
      "2019-01-24 17:34:10,448 epoch 90 - iter 42/72 - loss 0.36082893\n",
      "2019-01-24 17:34:14,757 epoch 90 - iter 49/72 - loss 0.34961552\n",
      "2019-01-24 17:34:19,427 epoch 90 - iter 56/72 - loss 0.35603963\n",
      "2019-01-24 17:34:24,379 epoch 90 - iter 63/72 - loss 0.35473538\n",
      "2019-01-24 17:34:29,042 epoch 90 - iter 70/72 - loss 0.33531687\n",
      "2019-01-24 17:34:29,310 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:34:29,311 EPOCH 90 done: loss 0.3340 - lr 0.0002 - bad epochs 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-24 17:34:31,692 DEV  : loss 0.23700468 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:34:39,820 TEST : loss 0.41780066 - f-score 0.9218 - acc 0.9218\n",
      "2019-01-24 17:34:39,825 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:34:40,617 epoch 91 - iter 0/72 - loss 0.20189869\n",
      "2019-01-24 17:34:45,317 epoch 91 - iter 7/72 - loss 0.28900978\n",
      "2019-01-24 17:34:49,708 epoch 91 - iter 14/72 - loss 0.26456805\n",
      "2019-01-24 17:34:54,271 epoch 91 - iter 21/72 - loss 0.25048022\n",
      "2019-01-24 17:34:59,472 epoch 91 - iter 28/72 - loss 0.30544078\n",
      "2019-01-24 17:35:03,981 epoch 91 - iter 35/72 - loss 0.31052737\n",
      "2019-01-24 17:35:08,207 epoch 91 - iter 42/72 - loss 0.34189788\n",
      "2019-01-24 17:35:12,991 epoch 91 - iter 49/72 - loss 0.34325391\n",
      "2019-01-24 17:35:17,204 epoch 91 - iter 56/72 - loss 0.33604837\n",
      "2019-01-24 17:35:21,698 epoch 91 - iter 63/72 - loss 0.34048313\n",
      "2019-01-24 17:35:26,410 epoch 91 - iter 70/72 - loss 0.32573955\n",
      "2019-01-24 17:35:26,756 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:35:26,758 EPOCH 91 done: loss 0.3249 - lr 0.0002 - bad epochs 3\n",
      "2019-01-24 17:35:28,269 DEV  : loss 0.23677477 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:35:35,834 TEST : loss 0.41774002 - f-score 0.9218 - acc 0.9218\n",
      "2019-01-24 17:35:38,390 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:35:38,996 epoch 92 - iter 0/72 - loss 0.06043696\n",
      "2019-01-24 17:35:43,831 epoch 92 - iter 7/72 - loss 0.46824205\n",
      "2019-01-24 17:35:48,243 epoch 92 - iter 14/72 - loss 0.44742951\n",
      "2019-01-24 17:35:52,192 epoch 92 - iter 21/72 - loss 0.40280957\n",
      "2019-01-24 17:35:56,779 epoch 92 - iter 28/72 - loss 0.40452328\n",
      "2019-01-24 17:36:01,525 epoch 92 - iter 35/72 - loss 0.39377913\n",
      "2019-01-24 17:36:05,880 epoch 92 - iter 42/72 - loss 0.40614953\n",
      "2019-01-24 17:36:10,090 epoch 92 - iter 49/72 - loss 0.36678877\n",
      "2019-01-24 17:36:14,388 epoch 92 - iter 56/72 - loss 0.35822442\n",
      "2019-01-24 17:36:19,035 epoch 92 - iter 63/72 - loss 0.37247014\n",
      "2019-01-24 17:36:23,627 epoch 92 - iter 70/72 - loss 0.37277145\n",
      "2019-01-24 17:36:23,887 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:36:23,889 EPOCH 92 done: loss 0.3796 - lr 0.0002 - bad epochs 0\n",
      "2019-01-24 17:36:25,366 DEV  : loss 0.23647131 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:36:33,621 TEST : loss 0.41758934 - f-score 0.9218 - acc 0.9218\n",
      "2019-01-24 17:36:33,625 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:36:34,312 epoch 93 - iter 0/72 - loss 0.24370882\n",
      "2019-01-24 17:36:39,142 epoch 93 - iter 7/72 - loss 0.41570662\n",
      "2019-01-24 17:36:43,590 epoch 93 - iter 14/72 - loss 0.36124634\n",
      "2019-01-24 17:36:48,744 epoch 93 - iter 21/72 - loss 0.33801893\n",
      "2019-01-24 17:36:53,696 epoch 93 - iter 28/72 - loss 0.29351854\n",
      "2019-01-24 17:36:58,420 epoch 93 - iter 35/72 - loss 0.29555461\n",
      "2019-01-24 17:37:03,187 epoch 93 - iter 42/72 - loss 0.31208877\n",
      "2019-01-24 17:37:08,067 epoch 93 - iter 49/72 - loss 0.33816668\n",
      "2019-01-24 17:37:12,443 epoch 93 - iter 56/72 - loss 0.35676586\n",
      "2019-01-24 17:37:17,021 epoch 93 - iter 63/72 - loss 0.35978210\n",
      "2019-01-24 17:37:21,614 epoch 93 - iter 70/72 - loss 0.35356732\n",
      "2019-01-24 17:37:21,898 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:37:21,900 EPOCH 93 done: loss 0.3524 - lr 0.0002 - bad epochs 1\n",
      "2019-01-24 17:37:23,299 DEV  : loss 0.23611672 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:37:32,062 TEST : loss 0.41746056 - f-score 0.9218 - acc 0.9218\n",
      "2019-01-24 17:37:32,066 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:37:32,775 epoch 94 - iter 0/72 - loss 0.31583977\n",
      "2019-01-24 17:37:37,373 epoch 94 - iter 7/72 - loss 0.47625109\n",
      "2019-01-24 17:37:41,744 epoch 94 - iter 14/72 - loss 0.34340079\n",
      "2019-01-24 17:37:46,423 epoch 94 - iter 21/72 - loss 0.33269979\n",
      "2019-01-24 17:37:51,082 epoch 94 - iter 28/72 - loss 0.31537909\n",
      "2019-01-24 17:37:55,311 epoch 94 - iter 35/72 - loss 0.33062521\n",
      "2019-01-24 17:37:59,657 epoch 94 - iter 42/72 - loss 0.34397261\n",
      "2019-01-24 17:38:03,965 epoch 94 - iter 49/72 - loss 0.36221973\n",
      "2019-01-24 17:38:08,387 epoch 94 - iter 56/72 - loss 0.33834078\n",
      "2019-01-24 17:38:12,758 epoch 94 - iter 63/72 - loss 0.34982013\n",
      "2019-01-24 17:38:17,704 epoch 94 - iter 70/72 - loss 0.34934949\n",
      "2019-01-24 17:38:17,974 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:38:17,976 EPOCH 94 done: loss 0.3482 - lr 0.0002 - bad epochs 2\n",
      "2019-01-24 17:38:19,552 DEV  : loss 0.23632306 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:38:27,561 TEST : loss 0.41753742 - f-score 0.9218 - acc 0.9218\n",
      "2019-01-24 17:38:27,564 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:38:28,325 epoch 95 - iter 0/72 - loss 0.53736567\n",
      "2019-01-24 17:38:33,124 epoch 95 - iter 7/72 - loss 0.31047260\n",
      "2019-01-24 17:38:38,057 epoch 95 - iter 14/72 - loss 0.29617965\n",
      "2019-01-24 17:38:42,817 epoch 95 - iter 21/72 - loss 0.28075531\n",
      "2019-01-24 17:38:47,246 epoch 95 - iter 28/72 - loss 0.26526703\n",
      "2019-01-24 17:38:52,088 epoch 95 - iter 35/72 - loss 0.24700883\n",
      "2019-01-24 17:38:56,541 epoch 95 - iter 42/72 - loss 0.27905227\n",
      "2019-01-24 17:39:01,823 epoch 95 - iter 49/72 - loss 0.33295209\n",
      "2019-01-24 17:39:06,360 epoch 95 - iter 56/72 - loss 0.34828276\n",
      "2019-01-24 17:39:10,908 epoch 95 - iter 63/72 - loss 0.34789978\n",
      "2019-01-24 17:39:15,479 epoch 95 - iter 70/72 - loss 0.35786518\n",
      "2019-01-24 17:39:15,811 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:39:15,813 EPOCH 95 done: loss 0.3565 - lr 0.0002 - bad epochs 3\n",
      "2019-01-24 17:39:17,283 DEV  : loss 0.23622803 - f-score 0.9231 - acc 0.9231\n",
      "2019-01-24 17:39:26,082 TEST : loss 0.41760322 - f-score 0.9218 - acc 0.9218\n",
      "Epoch    94: reducing learning rate of group 0 to 9.7656e-05.\n",
      "2019-01-24 17:39:26,085 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:39:26,086 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:39:26,087 learning rate too small - quitting training!\n",
      "2019-01-24 17:39:26,088 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:39:28,735 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-24 17:39:28,737 Testing using best model ...\n",
      "2019-01-24 17:39:37,570 MICRO_AVG: acc 0.9218 - f1-score 0.9218\n",
      "2019-01-24 17:39:37,572 MARCO_AVG: acc 0.4629 - f1-score 0.4771\n",
      "2019-01-24 17:39:37,574 CONCEPT    tp: 450 - fp: 11 - fn: 44 - tn: 450 - precision: 0.9761 - recall: 0.9109 - accuracy: 0.9424 - f1-score: 0.9424\n",
      "2019-01-24 17:39:37,575 CONCEPT\"   tp: 0 - fp: 0 - fn: 1 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-01-24 17:39:37,576 EQUATION   tp: 110 - fp: 8 - fn: 14 - tn: 110 - precision: 0.9322 - recall: 0.8871 - accuracy: 0.9091 - f1-score: 0.9091\n",
      "2019-01-24 17:39:37,577 O\"         tp: 0 - fp: 0 - fn: 17 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-01-24 17:39:37,578 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.9218,\n",
       " 'dev_score_history': [0.3151,\n",
       "  0.6178,\n",
       "  0.6339,\n",
       "  0.6559,\n",
       "  0.5061,\n",
       "  0.6989,\n",
       "  0.7487,\n",
       "  0.6989,\n",
       "  0.7873,\n",
       "  0.7879,\n",
       "  0.8465,\n",
       "  0.8558,\n",
       "  0.7961,\n",
       "  0.8651,\n",
       "  0.8679,\n",
       "  0.8531,\n",
       "  0.8585,\n",
       "  0.8679,\n",
       "  0.8785,\n",
       "  0.8207,\n",
       "  0.8688,\n",
       "  0.8879,\n",
       "  0.8663,\n",
       "  0.8818,\n",
       "  0.9018,\n",
       "  0.9041,\n",
       "  0.8908,\n",
       "  0.9091,\n",
       "  0.9099,\n",
       "  0.8889,\n",
       "  0.9099,\n",
       "  0.9196,\n",
       "  0.9091,\n",
       "  0.9041,\n",
       "  0.914,\n",
       "  0.885,\n",
       "  0.9099,\n",
       "  0.914,\n",
       "  0.914,\n",
       "  0.9099,\n",
       "  0.9041,\n",
       "  0.9091,\n",
       "  0.9099,\n",
       "  0.9058,\n",
       "  0.914,\n",
       "  0.914,\n",
       "  0.9091,\n",
       "  0.914,\n",
       "  0.914,\n",
       "  0.914,\n",
       "  0.914,\n",
       "  0.9231,\n",
       "  0.914,\n",
       "  0.9133,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231,\n",
       "  0.9231],\n",
       " 'train_loss_history': [5.142053530541285,\n",
       "  2.0977647690227395,\n",
       "  1.7451992603521083,\n",
       "  1.5974425588036671,\n",
       "  1.4295114601248975,\n",
       "  1.4109587617110704,\n",
       "  1.234514915018111,\n",
       "  1.1356432374137266,\n",
       "  1.0268281082059667,\n",
       "  0.9908322836421446,\n",
       "  0.916362888297717,\n",
       "  0.8580900896332443,\n",
       "  0.8540557872198591,\n",
       "  0.8615449654956703,\n",
       "  0.8221834108318378,\n",
       "  0.7592710163027819,\n",
       "  0.7557880091384961,\n",
       "  0.7129062180558823,\n",
       "  0.7172073258061724,\n",
       "  0.673592927005405,\n",
       "  0.6084175538410486,\n",
       "  0.6366595437996014,\n",
       "  0.5576830922067819,\n",
       "  0.6162866557287261,\n",
       "  0.5958847042135584,\n",
       "  0.5588828692672442,\n",
       "  0.6071737352979125,\n",
       "  0.5226823584336243,\n",
       "  0.5664899118215251,\n",
       "  0.4808202381460147,\n",
       "  0.48540189735516287,\n",
       "  0.47148139912639986,\n",
       "  0.494027823222828,\n",
       "  0.46279233863927566,\n",
       "  0.47967463760509765,\n",
       "  0.4457682101990977,\n",
       "  0.44714566188546345,\n",
       "  0.4606977926435726,\n",
       "  0.4588285544001183,\n",
       "  0.44880611485736716,\n",
       "  0.4576414968297441,\n",
       "  0.4554000427617362,\n",
       "  0.3901102403860665,\n",
       "  0.39988451994913077,\n",
       "  0.4147096717112005,\n",
       "  0.4027590956514418,\n",
       "  0.3826847463153737,\n",
       "  0.41473765479844166,\n",
       "  0.39730191972892254,\n",
       "  0.3913435256570016,\n",
       "  0.3648283060367355,\n",
       "  0.3743453870369436,\n",
       "  0.3782577518829386,\n",
       "  0.3733038745497152,\n",
       "  0.3675985704227165,\n",
       "  0.37972369396806754,\n",
       "  0.3814120742115521,\n",
       "  0.3738521881555058,\n",
       "  0.3463278857828598,\n",
       "  0.38534936252679286,\n",
       "  0.3843950721476487,\n",
       "  0.3414362978903885,\n",
       "  0.37234687972413716,\n",
       "  0.3868777968286684,\n",
       "  0.38067478090459345,\n",
       "  0.40109665672907646,\n",
       "  0.361352675110559,\n",
       "  0.34347053872342176,\n",
       "  0.34245934459212996,\n",
       "  0.34660083481430326,\n",
       "  0.3493753537333153,\n",
       "  0.3507309528569912,\n",
       "  0.369144874515893,\n",
       "  0.3611349074895943,\n",
       "  0.32569534890435337,\n",
       "  0.32702942116121514,\n",
       "  0.3484527014264513,\n",
       "  0.3645565958202852,\n",
       "  0.3290966053586004,\n",
       "  0.3416247261244704,\n",
       "  0.3603075751606073,\n",
       "  0.3374388396661567,\n",
       "  0.37433429247242794,\n",
       "  0.3493810212178379,\n",
       "  0.36942606963174796,\n",
       "  0.3598867294716239,\n",
       "  0.3513824495502022,\n",
       "  0.3289093716214593,\n",
       "  0.3447112324257683,\n",
       "  0.3340468291701167,\n",
       "  0.3248903896661246,\n",
       "  0.3795679630495278,\n",
       "  0.3523618590669745,\n",
       "  0.34824076392889963,\n",
       "  0.3565084502551703],\n",
       " 'dev_loss_history': [1.9315531253814697,\n",
       "  1.1667351722717285,\n",
       "  1.008709192276001,\n",
       "  0.8743099570274353,\n",
       "  1.2801944017410278,\n",
       "  0.7219729423522949,\n",
       "  0.6524118781089783,\n",
       "  0.8051457405090332,\n",
       "  0.6649176478385925,\n",
       "  0.6388765573501587,\n",
       "  0.4799428880214691,\n",
       "  0.5333028435707092,\n",
       "  0.5644381642341614,\n",
       "  0.4812048375606537,\n",
       "  0.42907968163490295,\n",
       "  0.45232054591178894,\n",
       "  0.4509746730327606,\n",
       "  0.42186570167541504,\n",
       "  0.43519794940948486,\n",
       "  0.4170612394809723,\n",
       "  0.37498822808265686,\n",
       "  0.3811446726322174,\n",
       "  0.3616413474082947,\n",
       "  0.327889621257782,\n",
       "  0.3058648109436035,\n",
       "  0.3126952052116394,\n",
       "  0.3474138677120209,\n",
       "  0.3055269122123718,\n",
       "  0.28115910291671753,\n",
       "  0.35440823435783386,\n",
       "  0.27984461188316345,\n",
       "  0.2781008780002594,\n",
       "  0.2704641819000244,\n",
       "  0.2992560863494873,\n",
       "  0.28934842348098755,\n",
       "  0.28967350721359253,\n",
       "  0.27930381894111633,\n",
       "  0.27134186029434204,\n",
       "  0.26097774505615234,\n",
       "  0.2720607817173004,\n",
       "  0.28879454731941223,\n",
       "  0.2885707914829254,\n",
       "  0.26586076617240906,\n",
       "  0.2760457396507263,\n",
       "  0.2704925537109375,\n",
       "  0.27821314334869385,\n",
       "  0.28250280022621155,\n",
       "  0.28002068400382996,\n",
       "  0.27073296904563904,\n",
       "  0.2564001977443695,\n",
       "  0.26838675141334534,\n",
       "  0.25774505734443665,\n",
       "  0.26685458421707153,\n",
       "  0.2706895172595978,\n",
       "  0.2747986912727356,\n",
       "  0.24970273673534393,\n",
       "  0.23992571234703064,\n",
       "  0.25119656324386597,\n",
       "  0.24821695685386658,\n",
       "  0.2538817822933197,\n",
       "  0.2504674196243286,\n",
       "  0.24071063101291656,\n",
       "  0.25640061497688293,\n",
       "  0.25156375765800476,\n",
       "  0.22864964604377747,\n",
       "  0.25279131531715393,\n",
       "  0.24623875319957733,\n",
       "  0.24097605049610138,\n",
       "  0.2443840205669403,\n",
       "  0.24249567091464996,\n",
       "  0.2380775809288025,\n",
       "  0.24097469449043274,\n",
       "  0.24022097885608673,\n",
       "  0.23717288672924042,\n",
       "  0.23867450654506683,\n",
       "  0.23802238702774048,\n",
       "  0.2380547970533371,\n",
       "  0.2357158064842224,\n",
       "  0.23759041726589203,\n",
       "  0.23756137490272522,\n",
       "  0.23526769876480103,\n",
       "  0.23602385818958282,\n",
       "  0.23560696840286255,\n",
       "  0.23622627556324005,\n",
       "  0.2355586439371109,\n",
       "  0.2350219041109085,\n",
       "  0.23601052165031433,\n",
       "  0.23650404810905457,\n",
       "  0.23663148283958435,\n",
       "  0.23700468242168427,\n",
       "  0.2367747724056244,\n",
       "  0.23647131025791168,\n",
       "  0.23611672222614288,\n",
       "  0.2363230586051941,\n",
       "  0.23622803390026093]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train('resources/taggers/ner-equations-01-23-2019',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The momentum is defined to be the mass <B-CONCEPT> of an object m times its velocity.\n"
     ]
    }
   ],
   "source": [
    "model = SequenceTagger.load_from_file('resources/taggers/ner-01-23-2019/final-model.pt')\n",
    "sentence = Sentence('The momentum is defined to be the mass of an object m times its velocity.')\n",
    "model.predict(sentence)\n",
    "print(sentence.to_tagged_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
